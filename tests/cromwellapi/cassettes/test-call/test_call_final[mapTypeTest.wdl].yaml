interactions:
- request:
    body: "--df8782ef690d7bb24777f664146bf4e3\r\nContent-Disposition: form-data; name=\"workflowSource\";
      filename=\"mapTypeTest.wdl\"\r\nContent-Type: application/octet-stream\r\n\r\nversion
      1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n
      \       Array[String] samples\n        Map[String, String] sample_metadata\n
      \       Map[String, Int] read_lengths\n\n        # New test inputs\n        Map[String,
      Map[String, String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
      \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
      {\n                \"sample3\": \"normal\",\n                \"sample4\": \"tumor\"\n
      \           }\n        }\n        # We need to provide keys as arrays since
      WDL 1.0 doesn't have a keys() function\n        Array[String] patient_ids =
      [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map processing\n    scatter
      (patient_id in patient_ids) {\n        call process_nested_map {\n            input:\n
      \               patient_id = patient_id,\n                patient_data = nested_map[patient_id],\n
      \               # We need to provide the sample names explicitly\n                samples_for_patient
      = if patient_id == \"patient1\" then [\"sample1\", \"sample2\"] else [\"sample3\",
      \"sample4\"]\n        }\n    }\n\n    # Original sample processing with output
      map generation\n    scatter (sample in samples) {\n        call process_sample
      {\n            input:\n                sample_name = sample,\n                sample_type
      = sample_metadata[sample],\n                read_length = read_lengths[sample]\n
      \       }\n    }\n\n    # Aggregate results into a map\n    call create_result_map
      {\n        input:\n            sample_names = samples,\n            processing_messages
      = process_sample.message\n    }\n\n    output {\n        Map[String, String]
      result_map = create_result_map.output_map\n        Array[String] nested_map_results
      = process_nested_map.message\n    }\n}\n\ntask process_nested_map {\n    input
      {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
      samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
      first_sample = samples_for_patient[0]\n    # Then use it to index the patient
      data\n    String sample_type = patient_data[first_sample]\n\n    command {\n
      \       echo \"Processing patient ${patient_id} with sample type ${sample_type}\"\n
      \       for sample in ${sep=' ' samples_for_patient}; do\n            echo \"Sample:
      $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n
      \   }\n\n    runtime {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask
      process_sample {\n    input {\n        String sample_name\n        String sample_type\n
      \       Int read_length\n    }\n\n    command <<<\n        echo \"Processing
      ~{sample_name} (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n
      \   output {\n        String message = read_string(stdout())\n    }\n\n    runtime
      {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map
      {\n    input {\n        Array[String] sample_names\n        Array[String] processing_messages\n
      \   }\n\n    command <<<\n        python <<CODE\n        samples = '~{sep=\",\"
      sample_names}'.split(',')\n        messages = '~{sep=\",\" processing_messages}'.split(',')\n
      \       result = dict(zip(samples, messages))\n        with open('output.txt',
      'w') as f:\n            for sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n
      \       CODE\n    >>>\n\n    output {\n        Map[String, String] output_map
      = read_map('output.txt')\n    }\n\n    runtime {\n        docker: \"python:3.8-slim\"\n
      \   }\n}\r\n--df8782ef690d7bb24777f664146bf4e3\r\nContent-Disposition: form-data;
      name=\"workflowInputs\"; filename=\"inputs.json\"\r\nContent-Type: application/json\r\n\r\n{\n
      \   \"enhanced_map_test.samples\": [\"sample1\", \"sample2\", \"sample3\"],\n
      \   \"enhanced_map_test.sample_metadata\": {\n        \"sample1\": \"normal\",\n
      \       \"sample2\": \"tumor\",\n        \"sample3\": \"normal\"\n    },\n    \"enhanced_map_test.read_lengths\":
      {\n        \"sample1\": 100,\n        \"sample2\": 150,\n        \"sample3\":
      100\n    },\n    \"enhanced_map_test.nested_map\": {\n        \"patient1\":
      {\n            \"sample1\": \"normal\",\n            \"sample2\": \"tumor\"\n
      \       },\n        \"patient2\": {\n            \"sample3\": \"normal\",\n
      \           \"sample4\": \"tumor\"\n        }\n    },\n    \"enhanced_map_test.patient_ids\":
      [\"patient1\", \"patient2\"]\n}\r\n--df8782ef690d7bb24777f664146bf4e3\r\nContent-Disposition:
      form-data; name=\"workflowOptions\"; filename=\"options.json\"\r\nContent-Type:
      application/json\r\n\r\n{\n    \"workflow_failure_mode\": \"ContinueWhilePossible\",\n
      \   \"write_to_cache\": false,\n    \"read_from_cache\": false\n}\n\r\n--df8782ef690d7bb24777f664146bf4e3--\r\n"
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '4653'
      content-type:
      - multipart/form-data; boundary=df8782ef690d7bb24777f664146bf4e3
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: POST
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1
  response:
    body:
      string: '{"id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","status":"Submitted"}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '66'
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:32:51 GMT
      Server:
      - nginx/1.25.3
    status:
      code: 201
      message: Created
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:32:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:42 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:33:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:34:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:35:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:09 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:14 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:25 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:30 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:35 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:40 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:45 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:50 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:36:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:20 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:25 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:30 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:46 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:51 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:37:56 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:01 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:38:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:42 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:39:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:40:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:09 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:14 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:41:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:20 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:25 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:30 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:35 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:40 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:45 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:50 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:42:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:46 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:51 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:43:56 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:01 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:42 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:44:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:45:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:46:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:09 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:14 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:47:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:20 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:25 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:30 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:35 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:40 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:45 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:50 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:48:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:46 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:51 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:49:56 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:01 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:42 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:50:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:51:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:52:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:09 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:14 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:53:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:20 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:25 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:30 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow enhanced_map_test
        {\n    input {\n        # Original inputs\n        Array[String] samples\n        Map[String,
        String] sample_metadata\n        Map[String, Int] read_lengths\n\n        #
        New test inputs\n        Map[String, Map[String, String]] nested_map = {\n            \"patient1\":
        {\n                \"sample1\": \"normal\",\n                \"sample2\":
        \"tumor\"\n            },\n            \"patient2\": {\n                \"sample3\":
        \"normal\",\n                \"sample4\": \"tumor\"\n            }\n        }\n        #
        We need to provide keys as arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:35 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4515'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:40 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5254'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:45 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '10851'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:50 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:54:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:46 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:51 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:55:56 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:01 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11076'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"jobId":"29236728","backend":"gizmo","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"jobId":"29236730","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11172'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"jobId":"29236731","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '12861'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '13791'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.process_sample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"jobId":"29236729","backend":"gizmo","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0"},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '13791'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"jobId":"29236732","backend":"gizmo","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","attempt":1,"start":"2025-08-11T18:54:39.385Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1"}],"enhanced_map_test.create_result_map":[{"executionStatus":"QueuedInCromwell","shardIndex":-1,"backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:42 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '14940'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17165'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:56:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:57:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Running","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"jobId":"29236745","backend":"gizmo","attempt":1,"start":"2025-08-11T18:56:38.723Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '17210'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Done","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"outputs":{"output_map":{"sample2":"Processing
        sample2 (tumor) with read length 150","sample1":"Processing sample1 (normal)
        with read length 100","sample3":"Processing sample3 (normal) with read length
        100"}},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"returnCode":0,"jobId":"29236745","backend":"gizmo","start":"2025-08-11T18:56:38.723Z","end":"2025-08-11T18:58:29.667Z","dockerImageUsed":"python@sha256:1d52838af602b4b5a831beb13a0e4d073280665ea7be7f69ce2382f29c5a613f","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:58:29.373Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:58:29.667Z"},{"startTime":"2025-08-11T18:56:40.943Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:56:40.943Z"},{"startTime":"2025-08-11T18:56:40.943Z","description":"PreparingJob","endTime":"2025-08-11T18:56:40.961Z"},{"startTime":"2025-08-11T18:56:38.723Z","description":"Pending","endTime":"2025-08-11T18:56:38.723Z"},{"startTime":"2025-08-11T18:56:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:58:29.373Z"},{"startTime":"2025-08-11T18:56:38.723Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:56:40.943Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '18239'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmok20.fhcrc.org:46789
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmok20.fhcrc.org:46789/api/workflows/v1/64ae2c60-7d42-4adc-bab1-0d92ab064893/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"enhanced_map_test","workflowProcessingEvents":[{"cromwellId":"cromid-20c7f37","description":"Finished","timestamp":"2025-08-11T18:58:30.926Z","cromwellVersion":"87"},{"cromwellId":"cromid-20c7f37","description":"PickedUp","timestamp":"2025-08-11T18:54:35.270Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow enhanced_map_test {\n    input {\n        # Original inputs\n        Array[String]
        samples\n        Map[String, String] sample_metadata\n        Map[String,
        Int] read_lengths\n\n        # New test inputs\n        Map[String, Map[String,
        String]] nested_map = {\n            \"patient1\": {\n                \"sample1\":
        \"normal\",\n                \"sample2\": \"tumor\"\n            },\n            \"patient2\":
        {\n                \"sample3\": \"normal\",\n                \"sample4\":
        \"tumor\"\n            }\n        }\n        # We need to provide keys as
        arrays since WDL 1.0 doesn''t have a keys() function\n        Array[String]
        patient_ids = [\"patient1\", \"patient2\"]\n    }\n\n    # Test nested map
        processing\n    scatter (patient_id in patient_ids) {\n        call process_nested_map
        {\n            input:\n                patient_id = patient_id,\n                patient_data
        = nested_map[patient_id],\n                # We need to provide the sample
        names explicitly\n                samples_for_patient = if patient_id == \"patient1\"
        then [\"sample1\", \"sample2\"] else [\"sample3\", \"sample4\"]\n        }\n    }\n\n    #
        Original sample processing with output map generation\n    scatter (sample
        in samples) {\n        call process_sample {\n            input:\n                sample_name
        = sample,\n                sample_type = sample_metadata[sample],\n                read_length
        = read_lengths[sample]\n        }\n    }\n\n    # Aggregate results into a
        map\n    call create_result_map {\n        input:\n            sample_names
        = samples,\n            processing_messages = process_sample.message\n    }\n\n    output
        {\n        Map[String, String] result_map = create_result_map.output_map\n        Array[String]
        nested_map_results = process_nested_map.message\n    }\n}\n\ntask process_nested_map
        {\n    input {\n        String patient_id\n        Map[String, String] patient_data\n        Array[String]
        samples_for_patient\n    }\n\n    # First get the first sample ID\n    String
        first_sample = samples_for_patient[0]\n    # Then use it to index the patient
        data\n    String sample_type = patient_data[first_sample]\n\n    command {\n        echo
        \"Processing patient ${patient_id} with sample type ${sample_type}\"\n        for
        sample in ${sep='' '' samples_for_patient}; do\n            echo \"Sample:
        $sample\"\n        done\n    }\n\n    output {\n        String message = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask process_sample
        {\n    input {\n        String sample_name\n        String sample_type\n        Int
        read_length\n    }\n\n    command <<<\n        echo \"Processing ~{sample_name}
        (~{sample_type}) with read length ~{read_length}\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask create_result_map {\n    input
        {\n        Array[String] sample_names\n        Array[String] processing_messages\n    }\n\n    command
        <<<\n        python <<CODE\n        samples = ''~{sep=\",\" sample_names}''.split('','')\n        messages
        = ''~{sep=\",\" processing_messages}''.split('','')\n        result = dict(zip(samples,
        messages))\n        with open(''output.txt'', ''w'') as f:\n            for
        sample, message in result.items():\n                f.write(f\"{sample}\\t{message}\\n\")\n        CODE\n    >>>\n\n    output
        {\n        Map[String, String] output_map = read_map(''output.txt'')\n    }\n\n    runtime
        {\n        docker: \"python:3.8-slim\"\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"enhanced_map_test.nested_map\":{\"patient1\":{\"sample1\":\"normal\",\"sample2\":\"tumor\"},\"patient2\":{\"sample3\":\"normal\",\"sample4\":\"tumor\"}},\"enhanced_map_test.patient_ids\":[\"patient1\",\"patient2\"],\"enhanced_map_test.read_lengths\":{\"sample1\":100,\"sample2\":150,\"sample3\":100},\"enhanced_map_test.sample_metadata\":{\"sample1\":\"normal\",\"sample2\":\"tumor\",\"sample3\":\"normal\"},\"enhanced_map_test.samples\":[\"sample1\",\"sample2\",\"sample3\"]}","workflowUrl":"","labels":"{}"},"calls":{"enhanced_map_test.process_sample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample1 (normal) with read length 100\"","shardIndex":0,"outputs":{"message":"Processing
        sample1 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample1","sample_type":"normal"},"returnCode":0,"jobId":"29236729","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:36.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.970Z"},{"startTime":"2025-08-11T18:54:40.970Z","description":"RunningJob","endTime":"2025-08-11T18:56:35.882Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:35.882Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:36.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample2 (tumor) with read length 150\"","shardIndex":1,"outputs":{"message":"Processing
        sample2 (tumor) with read length 150"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":150,"sample_name":"sample2","sample_type":"tumor"},"returnCode":0,"jobId":"29236728","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:20.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.975Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.975Z","description":"RunningJob","endTime":"2025-08-11T18:56:20.428Z"},{"startTime":"2025-08-11T18:56:20.428Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:20.668Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing sample3 (normal) with read length 100\"","shardIndex":2,"outputs":{"message":"Processing
        sample3 (normal) with read length 100"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"read_length":100,"sample_name":"sample3","sample_type":"normal"},"returnCode":0,"jobId":"29236730","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:24.668Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_sample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.961Z"},{"startTime":"2025-08-11T18:54:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:56:24.632Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:24.632Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:24.669Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"}]}],"enhanced_map_test.process_nested_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient1 with sample type normal\"\nfor sample in sample1
        sample2; do\n    echo \"Sample: $sample\"\ndone","shardIndex":0,"outputs":{"message":"Processing
        patient patient1 with sample type normal\nSample: sample1\nSample: sample2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient1","first_sample":"sample1","patient_data":{"sample2":"tumor","sample1":"normal"},"samples_for_patient":["sample1","sample2"]},"returnCode":0,"jobId":"29236731","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:28.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:56:28.264Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:28.667Z"},{"startTime":"2025-08-11T18:54:40.972Z","description":"RunningJob","endTime":"2025-08-11T18:56:28.264Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.972Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing patient patient2 with sample type normal\"\nfor sample in sample3
        sample4; do\n    echo \"Sample: $sample\"\ndone","shardIndex":1,"outputs":{"message":"Processing
        patient patient2 with sample type normal\nSample: sample3\nSample: sample4"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_type":"normal","patient_id":"patient2","first_sample":"sample3","patient_data":{"sample4":"tumor","sample3":"normal"},"samples_for_patient":["sample3","sample4"]},"returnCode":0,"jobId":"29236732","backend":"gizmo","start":"2025-08-11T18:54:39.385Z","end":"2025-08-11T18:56:40.667Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-process_nested_map/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:56:40.182Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:56:40.667Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.966Z","description":"RunningJob","endTime":"2025-08-11T18:56:40.182Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:54:40.942Z"},{"startTime":"2025-08-11T18:54:40.942Z","description":"PreparingJob","endTime":"2025-08-11T18:54:40.966Z"},{"startTime":"2025-08-11T18:54:39.385Z","description":"Pending","endTime":"2025-08-11T18:54:39.385Z"}]}],"enhanced_map_test.create_result_map":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stdout","backendStatus":"Done","commandLine":"python
        <<CODE\nsamples = ''sample1,sample2,sample3''.split('','')\nmessages = ''Processing
        sample1 (normal) with read length 100,Processing sample2 (tumor) with read
        length 150,Processing sample3 (normal) with read length 100''.split('','')\nresult
        = dict(zip(samples, messages))\nwith open(''output.txt'', ''w'') as f:\n    for
        sample, message in result.items():\n        f.write(f\"{sample}\\t{message}\\n\")\nCODE","shardIndex":-1,"outputs":{"output_map":{"sample2":"Processing
        sample2 (tumor) with read length 150","sample1":"Processing sample1 (normal)
        with read length 100","sample3":"Processing sample3 (normal) with read length
        100"}},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"python:3.8-slim","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_names":["sample1","sample2","sample3"],"processing_messages":["Processing
        sample1 (normal) with read length 100","Processing sample2 (tumor) with read
        length 150","Processing sample3 (normal) with read length 100"]},"returnCode":0,"jobId":"29236745","backend":"gizmo","start":"2025-08-11T18:56:38.723Z","end":"2025-08-11T18:58:29.667Z","dockerImageUsed":"python@sha256:1d52838af602b4b5a831beb13a0e4d073280665ea7be7f69ce2382f29c5a613f","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893/call-create_result_map","attempt":1,"executionEvents":[{"startTime":"2025-08-11T18:58:29.373Z","description":"UpdatingJobStore","endTime":"2025-08-11T18:58:29.667Z"},{"startTime":"2025-08-11T18:56:40.943Z","description":"WaitingForValueStore","endTime":"2025-08-11T18:56:40.943Z"},{"startTime":"2025-08-11T18:56:40.943Z","description":"PreparingJob","endTime":"2025-08-11T18:56:40.961Z"},{"startTime":"2025-08-11T18:56:38.723Z","description":"Pending","endTime":"2025-08-11T18:56:38.723Z"},{"startTime":"2025-08-11T18:56:40.961Z","description":"RunningJob","endTime":"2025-08-11T18:58:29.373Z"},{"startTime":"2025-08-11T18:56:38.723Z","description":"RequestingExecutionToken","endTime":"2025-08-11T18:56:40.943Z"}]}]},"outputs":{"enhanced_map_test.result_map":{"sample2":"Processing
        sample2 (tumor) with read length 150","sample1":"Processing sample1 (normal)
        with read length 100","sample3":"Processing sample3 (normal) with read length
        100"},"enhanced_map_test.nested_map_results":["Processing patient patient1
        with sample type normal\nSample: sample1\nSample: sample2","Processing patient
        patient2 with sample type normal\nSample: sample3\nSample: sample4"]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/enhanced_map_test/64ae2c60-7d42-4adc-bab1-0d92ab064893","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-08-11T18:58:30.926Z","start":"2025-08-11T18:54:35.271Z","id":"64ae2c60-7d42-4adc-bab1-0d92ab064893","inputs":{"read_lengths":{"sample2":150,"sample1":100,"sample3":100},"samples":["sample1","sample2","sample3"],"nested_map":{"patient2":{"sample4":"tumor","sample3":"normal"},"patient1":{"sample1":"normal","sample2":"tumor"}},"patient_ids":["patient1","patient2"],"sample_metadata":{"sample2":"tumor","sample1":"normal","sample3":"normal"}},"labels":{"cromwell-workflow-id":"cromwell-64ae2c60-7d42-4adc-bab1-0d92ab064893"},"submission":"2025-08-11T18:32:51.980Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Aug 2025 18:58:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '18824'
    status:
      code: 200
      message: OK
version: 1
