interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:38:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:39:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:40:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:09 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:14 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:41:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\nworkflow test_nonstandard_outputs
        {\n    call generate_diverse_outputs\n    \n    output {\n        File special_chars
        = generate_diverse_outputs.file_special_chars\n        File no_extension =
        generate_diverse_outputs.file_no_extension\n        File nested_output = generate_diverse_outputs.nested_file\n        File
        symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:20 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1899'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"QueuedInCromwell","shardIndex":-1,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:25 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2496'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:30 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3731'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Running","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063377","backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:35 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3775'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Running","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063377","backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:40 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3775'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Running","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063377","backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:45 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3775'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Running","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063377","backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:50 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3775'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Running","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063377","backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:42:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3775'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Running","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063377","backend":"gizmo","attempt":1,"start":"2025-02-11T07:42:21.059Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3775'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/55941186-1c2a-4095-9887-646e7be2d0cf/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"test_nonstandard_outputs","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:20.009Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:42:59.820Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow test_nonstandard_outputs {\n    call generate_diverse_outputs\n    \n    output
        {\n        File special_chars = generate_diverse_outputs.file_special_chars\n        File
        no_extension = generate_diverse_outputs.file_no_extension\n        File nested_output
        = generate_diverse_outputs.nested_file\n        File symlink_file = generate_diverse_outputs.symlink_output\n        Array[File]
        glob_files = generate_diverse_outputs.pattern_files\n    }\n}\n\ntask generate_diverse_outputs
        {\n    command <<<\n        # File with special characters\n        echo \"test
        content\" > \"test@file#1.txt\"\n        \n        # File without extension\n        echo
        \"no extension\" > datafile\n        \n        # Nested directory output\n        mkdir
        -p nested/dir\n        echo \"nested content\" > nested/dir/test.txt\n        \n        #
        Create a symlink\n        echo \"original\" > original.txt\n        ln -s
        original.txt link.txt\n        \n        # Multiple pattern files\n        for
        i in {1..3}; do\n            echo \"pattern $i\" > \"pattern_$i.out\"\n        done\n    >>>\n\n    output
        {\n        File file_special_chars = \"test@file#1.txt\"\n        File file_no_extension
        = \"datafile\"\n        File nested_file = \"nested/dir/test.txt\"\n        File
        symlink_output = \"link.txt\"\n        Array[File] pattern_files = glob(\"pattern_*.out\")\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"test_nonstandard_outputs.generate_diverse_outputs":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stdout","backendStatus":"Done","commandLine":"#
        File with special characters\necho \"test content\" > \"test@file#1.txt\"\n\n#
        File without extension\necho \"no extension\" > datafile\n\n# Nested directory
        output\nmkdir -p nested/dir\necho \"nested content\" > nested/dir/test.txt\n\n#
        Create a symlink\necho \"original\" > original.txt\nln -s original.txt link.txt\n\n#
        Multiple pattern files\nfor i in {1..3}; do\n    echo \"pattern $i\" > \"pattern_$i.out\"\ndone","shardIndex":-1,"outputs":{"symlink_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/link.txt","file_no_extension":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/datafile","nested_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/nested/dir/test.txt","pattern_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/glob-4ded3a97b6654226f2cdd04e2711b93c/pattern_1.out","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/glob-4ded3a97b6654226f2cdd04e2711b93c/pattern_2.out","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/glob-4ded3a97b6654226f2cdd04e2711b93c/pattern_3.out"],"file_special_chars":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/test@file#1.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063377","backend":"gizmo","start":"2025-02-11T07:42:21.059Z","end":"2025-02-11T07:42:58.337Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:21.059Z","description":"Pending","endTime":"2025-02-11T07:42:21.059Z"},{"startTime":"2025-02-11T07:42:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:22.677Z"},{"startTime":"2025-02-11T07:42:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:42:22.689Z"},{"startTime":"2025-02-11T07:42:58.099Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:58.337Z"},{"startTime":"2025-02-11T07:42:22.689Z","description":"RunningJob","endTime":"2025-02-11T07:42:58.099Z"},{"startTime":"2025-02-11T07:42:21.059Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:22.677Z"}]}]},"outputs":{"test_nonstandard_outputs.symlink_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/link.txt","test_nonstandard_outputs.nested_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/nested/dir/test.txt","test_nonstandard_outputs.glob_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/glob-4ded3a97b6654226f2cdd04e2711b93c/pattern_1.out","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/glob-4ded3a97b6654226f2cdd04e2711b93c/pattern_2.out","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/glob-4ded3a97b6654226f2cdd04e2711b93c/pattern_3.out"],"test_nonstandard_outputs.no_extension":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/datafile","test_nonstandard_outputs.special_chars":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf/call-generate_diverse_outputs/execution/test@file#1.txt"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/test_nonstandard_outputs/55941186-1c2a-4095-9887-646e7be2d0cf","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:42:59.820Z","start":"2025-02-11T07:42:20.010Z","id":"55941186-1c2a-4095-9887-646e7be2d0cf","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-55941186-1c2a-4095-9887-646e7be2d0cf"},"submission":"2025-02-11T07:38:44.771Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7670'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/391c6089-ff50-45e5-b745-071a2b115ba5/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"ArrayOperations","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:41:59.986Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:42:54.092Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow ArrayOperations {\n    input {\n        # Input arrays for
        different tests\n        Array[String] strings\n        Array[String] additional_strings
        = []  # For testing array concatenation\n        Array[Array[String]] nested_arrays
        = []  # For testing nested arrays\n        Array[Int] numbers = [1, 2, 3,
        4, 5]  # Default integer array for numeric operations\n        Array[File]
        input_files = [] # Array of files to test file operations\n    }\n    \n    #
        Scatter operation to test processing of each element in an array\n    # Test
        empty arrays (original operation still works with empty input)\n    scatter
        (str in strings) {\n        call Uppercase { input: text = str }\n    }\n    \n    #
        Test array indexing (accessing first and last elements)\n    if (length(strings)
        > 0) {\n        call ValidateIndex { input: arr = strings }\n    }\n    \n    #
        Test array functions like sorting, length calculation, and flattening\n    call
        ArrayFunctions { \n        input: \n            arr = strings,\n            nested
        = nested_arrays\n    }\n    \n    # Test array concatenation and verify the
        combined length\n    Array[String] combined = flatten([strings, additional_strings])\n    call
        ArrayConcat {\n        input: \n            arr1 = strings,\n            arr2
        = additional_strings,\n            expected_length = length(combined)\n    }\n    \n    #
        Test integer array operations like summation and combining arrays\n    Array[Int]
        more_numbers = [6, 7, 8, 9, 10]  # Intermediate array declaration\n    call
        IntegerArrayOps {\n        input:\n            numbers = numbers,\n            additional_numbers
        = more_numbers\n    }\n\n    # Test file array operations like localization
        and content reading\n    if (length(input_files) > 0) {\n        call FileArrayOps
        {\n            input:\n                files = input_files\n        }\n    }\n    #
        Outputs to capture results of the tests\n    output {\n        Array[String]
        uppercased = Uppercase.out # Outputs from scatter task\n        Int? first_index
        = ValidateIndex.first_index # First index in string array\n        Int? last_index
        = ValidateIndex.last_index # Last index in string array\n        Array[String]
        sorted_array = ArrayFunctions.sorted # Sorted array\n        Array[Array[String]]
        processed_nested = ArrayFunctions.processed_nested # Processed nested array\n        Boolean
        concat_test_passed = ArrayConcat.test_passed # Result of concatenation test\n        Int
        array_length = ArrayFunctions.arr_length # Length of input array\n        Array[String]
        flattened = ArrayFunctions.flattened # Flattened nested arrays\n        #
        New outputs for integer array operations \n        Int sum_result = IntegerArrayOps.sum
        # Sum of integer array\n        Array[Int] combined_numbers = IntegerArrayOps.combined
        # Combined integer arrays\n        # New outputs for file array operations\n        Array[String]?
        file_contents = FileArrayOps.contents # Contents of files\n        Boolean?
        files_localized = FileArrayOps.localization_success # File localization status\n    }\n\n    parameter_meta
        {\n        # Descriptions for inputs\n        strings: \"Primary array of
        input strings\"\n        additional_strings: \"Secondary array for testing
        concatenation\"\n        nested_arrays: \"Array of arrays for testing nested
        array operations\"\n        numbers: \"Array of integers for testing numeric
        operations\"\n        input_files: \"Array of input files for testing file
        localization\"\n    }\n}\n\n# Task to convert string to uppercase (tests per-element
        processing)\ntask Uppercase {\n    input {\n        String text\n    }\n    \n    command
        <<<\n        echo \"~{text}\" | tr ''[:lower:]'' ''[:upper:]''\n    >>>\n    \n    output
        {\n        String out = read_string(stdout())\n    }\n    \n    runtime {\n        cpu:
        1\n        memory: \"1 GB\"\n    }\n}\n\n\n# Task to test indexing operations\ntask
        ValidateIndex {\n    input {\n        Array[String] arr\n    }\n    \n    command
        <<<\n        echo \"0\" > first_index.txt  # First index\n        echo \"~{length(arr)-1}\"
        > last_index.txt  # Last index\n    >>>\n    \n    output {\n        Int first_index
        = read_int(\"first_index.txt\")\n        Int last_index = read_int(\"last_index.txt\")\n    }\n    \n    runtime
        {\n        cpu: 1\n        memory: \"1 GB\"\n    }\n}\n\n# Task to test array
        functions\ntask ArrayFunctions {\n    input {\n        Array[String] arr\n        Array[Array[String]]
        nested\n    }\n    \n    command <<<\n        # Sort the input array using
        bash\n        echo \"~{sep=''\\n'' arr}\" | sort > sorted.txt\n        \n        #
        Get array length\n        echo \"~{length(arr)}\" > length.txt\n        \n        #
        Process nested arrays (flatten them)\n        echo \"~{sep=''\\n'' flatten(nested)}\"
        > flattened.txt\n    >>>\n    \n    output {\n        Array[String] sorted
        = read_lines(\"sorted.txt\")\n        Int arr_length = read_int(\"length.txt\")\n        Array[String]
        flattened = read_lines(\"flattened.txt\")\n        Array[Array[String]] processed_nested
        = nested  # Return the original nested array\n    }\n    \n    runtime {\n        cpu:
        1\n        memory: \"1 GB\"\n    }\n}\n\n# Task to test concatenation of two
        arrays\ntask ArrayConcat {\n    input {\n        Array[String] arr1\n        Array[String]
        arr2\n        Int expected_length\n    }\n    \n    command <<<\n        actual_length=$((
        ~{length(arr1)} + ~{length(arr2)} ))\n        if [ \"$actual_length\" -eq
        ~{expected_length} ]; then\n            echo \"true\"\n        else\n            echo
        \"false\"\n        fi\n    >>>\n    \n    output {\n        Boolean test_passed
        = read_boolean(stdout())\n    }\n    \n    runtime {\n        cpu: 1\n        memory:
        \"1 GB\"\n    }\n}\n\n# Task to test integer array operations\ntask IntegerArrayOps
        {\n    input {\n        Array[Int] numbers\n        Array[Int] additional_numbers\n    }\n    \n    command
        <<<\n        # Calculate sum of numbers to verify proper parsing\n        total=0\n        for
        num in ~{sep='' '' numbers}; do\n            total=$((total + num))\n        done\n        echo
        $total > sum.txt\n\n        # Combine arrays and write to file\n        echo
        \"~{sep=''\\n'' flatten([numbers, additional_numbers])}\" > combined.txt\n    >>>\n    \n    output
        {\n        Int sum = read_int(\"sum.txt\")\n        Array[Int] combined =
        read_lines(\"combined.txt\")\n    }\n    \n    runtime {\n        cpu: 1\n        memory:
        \"1 GB\"\n    }\n}\n\n# Task to test file array operations\ntask FileArrayOps
        {\n    input {\n        Array[File] files\n    }\n    \n    command <<<\n        #
        Test file localization by reading contents\n        for file in ~{sep='' ''
        files}; do\n            if [ -f \"$file\" ]; then\n                cat \"$file\"
        >> all_contents.txt\n                echo \"---\" >> all_contents.txt  # Separator
        between files\n            else\n                echo \"false\" > localization_success.txt\n                exit
        1\n            fi\n        done\n        echo \"true\" > localization_success.txt\n    >>>\n    \n    output
        {\n        Array[String] contents = read_lines(\"all_contents.txt\")\n        Boolean
        localization_success = read_boolean(\"localization_success.txt\")\n    }\n    \n    runtime
        {\n        cpu: 1\n        memory: \"1 GB\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"ArrayOperations.additional_strings\":[\"foo\",\"bar\"],\"ArrayOperations.input_files\":[\"arrayOperations/data/test1.txt\",\"arrayOperations/data/test2.txt\",\"arrayOperations/data/test3.txt\"],\"ArrayOperations.nested_arrays\":[[\"nested1\",\"nested2\"],[\"nested3\",\"nested4\"]],\"ArrayOperations.numbers\":[1,2,3,4,5],\"ArrayOperations.strings\":[\"hello\",\"world\",\"test\"]}","workflowUrl":"","labels":"{}"},"calls":{"ArrayOperations.ArrayConcat":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ArrayConcat/execution/stdout","backendStatus":"Done","commandLine":"actual_length=$((
        3 + 2 ))\nif [ \"$actual_length\" -eq 5 ]; then\n    echo \"true\"\nelse\n    echo
        \"false\"\nfi","shardIndex":-1,"outputs":{"test_passed":true},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"expected_length":5,"arr1":["hello","world","test"],"arr2":["foo","bar"]},"returnCode":0,"jobId":"9063371","backend":"gizmo","end":"2025-02-11T07:42:45.333Z","start":"2025-02-11T07:42:03.088Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ArrayConcat/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ArrayConcat","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"},{"startTime":"2025-02-11T07:42:12.703Z","description":"RunningJob","endTime":"2025-02-11T07:42:44.788Z"},{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.703Z"},{"startTime":"2025-02-11T07:42:44.788Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:45.333Z"},{"startTime":"2025-02-11T07:42:03.088Z","description":"Pending","endTime":"2025-02-11T07:42:03.088Z"},{"startTime":"2025-02-11T07:42:03.088Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"}]}],"ArrayOperations.FileArrayOps":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-FileArrayOps/execution/stdout","backendStatus":"Done","commandLine":"#
        Test file localization by reading contents\nfor file in /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-FileArrayOps/inputs/1330878614/test1.txt
        /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-FileArrayOps/inputs/1330878614/test2.txt
        /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-FileArrayOps/inputs/1330878614/test3.txt;
        do\n    if [ -f \"$file\" ]; then\n        cat \"$file\" >> all_contents.txt\n        echo
        \"---\" >> all_contents.txt  # Separator between files\n    else\n        echo
        \"false\" > localization_success.txt\n        exit 1\n    fi\ndone\necho \"true\"
        > localization_success.txt","shardIndex":-1,"outputs":{"localization_success":true,"contents":["Hello...---","...
        is it me you''re ...---","... looking for???---"]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"files":["arrayOperations/data/test1.txt","arrayOperations/data/test2.txt","arrayOperations/data/test3.txt"]},"returnCode":0,"jobId":"9063372","backend":"gizmo","end":"2025-02-11T07:42:47.333Z","start":"2025-02-11T07:42:04.108Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-FileArrayOps/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-FileArrayOps","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.693Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"},{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"},{"startTime":"2025-02-11T07:42:46.390Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:47.333Z"},{"startTime":"2025-02-11T07:42:12.693Z","description":"RunningJob","endTime":"2025-02-11T07:42:46.390Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"Pending","endTime":"2025-02-11T07:42:04.108Z"}]}],"ArrayOperations.ArrayFunctions":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ArrayFunctions/execution/stdout","backendStatus":"Done","commandLine":"#
        Sort the input array using bash\necho \"hello\nworld\ntest\" | sort > sorted.txt\n\n#
        Get array length\necho \"3\" > length.txt\n\n# Process nested arrays (flatten
        them)\necho \"nested1\nnested2\nnested3\nnested4\" > flattened.txt","shardIndex":-1,"outputs":{"arr_length":3,"sorted":["hello","test","world"],"flattened":["nested1","nested2","nested3","nested4"],"processed_nested":[["nested1","nested2"],["nested3","nested4"]]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"arr":["hello","world","test"],"nested":[["nested1","nested2"],["nested3","nested4"]]},"returnCode":0,"jobId":"9063368","backend":"gizmo","end":"2025-02-11T07:42:34.334Z","start":"2025-02-11T07:42:02.069Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ArrayFunctions/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ArrayFunctions","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:02.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:02.694Z"},{"startTime":"2025-02-11T07:42:02.069Z","description":"Pending","endTime":"2025-02-11T07:42:02.069Z"},{"startTime":"2025-02-11T07:42:33.923Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:34.334Z"},{"startTime":"2025-02-11T07:42:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:02.678Z"},{"startTime":"2025-02-11T07:42:02.069Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:02.678Z"},{"startTime":"2025-02-11T07:42:02.694Z","description":"RunningJob","endTime":"2025-02-11T07:42:33.923Z"}]}],"ArrayOperations.IntegerArrayOps":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-IntegerArrayOps/execution/stdout","backendStatus":"Done","commandLine":"        #
        Calculate sum of numbers to verify proper parsing\n        total=0\n        for
        num in 1 2 3 4 5; do\n            total=$((total + num))\n        done\n        echo
        $total > sum.txt\n\n        # Combine arrays and write to file\n        echo
        \"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\" > combined.txt","shardIndex":-1,"outputs":{"sum":15,"combined":[1,2,3,4,5,6,7,8,9,10]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"additional_numbers":[6,7,8,9,10],"numbers":[1,2,3,4,5]},"returnCode":0,"jobId":"9063373","backend":"gizmo","end":"2025-02-11T07:42:49.333Z","start":"2025-02-11T07:42:03.087Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-IntegerArrayOps/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-IntegerArrayOps","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:48.618Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:49.333Z"},{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.705Z"},{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"},{"startTime":"2025-02-11T07:42:03.088Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"},{"startTime":"2025-02-11T07:42:12.705Z","description":"RunningJob","endTime":"2025-02-11T07:42:48.618Z"},{"startTime":"2025-02-11T07:42:03.087Z","description":"Pending","endTime":"2025-02-11T07:42:03.088Z"}]}],"ArrayOperations.ValidateIndex":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ValidateIndex/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"0\" > first_index.txt  # First index\necho \"2\" > last_index.txt  # Last
        index","shardIndex":-1,"outputs":{"last_index":2,"first_index":0},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"arr":["hello","world","test"]},"returnCode":0,"jobId":"9063370","backend":"gizmo","end":"2025-02-11T07:42:48.333Z","start":"2025-02-11T07:42:04.108Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ValidateIndex/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-ValidateIndex","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:04.108Z","description":"Pending","endTime":"2025-02-11T07:42:04.108Z"},{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.688Z"},{"startTime":"2025-02-11T07:42:12.688Z","description":"RunningJob","endTime":"2025-02-11T07:42:47.620Z"},{"startTime":"2025-02-11T07:42:47.620Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:48.333Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"},{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"}]}],"ArrayOperations.Uppercase":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"hello\" | tr ''[:lower:]'' ''[:upper:]''","shardIndex":0,"outputs":{"out":"HELLO"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"text":"hello"},"returnCode":0,"jobId":"9063374","backend":"gizmo","end":"2025-02-11T07:42:44.332Z","start":"2025-02-11T07:42:04.108Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:12.690Z","description":"RunningJob","endTime":"2025-02-11T07:42:43.890Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"Pending","endTime":"2025-02-11T07:42:04.108Z"},{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.690Z"},{"startTime":"2025-02-11T07:42:43.890Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:44.332Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"},{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"world\" | tr ''[:lower:]'' ''[:upper:]''","shardIndex":1,"outputs":{"out":"WORLD"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"text":"world"},"returnCode":0,"jobId":"9063375","backend":"gizmo","end":"2025-02-11T07:42:51.333Z","start":"2025-02-11T07:42:04.108Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.696Z"},{"startTime":"2025-02-11T07:42:50.687Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:51.333Z"},{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"Pending","endTime":"2025-02-11T07:42:04.108Z"},{"startTime":"2025-02-11T07:42:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:42:50.687Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"test\" | tr ''[:lower:]'' ''[:upper:]''","shardIndex":2,"outputs":{"out":"TEST"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"text":"test"},"returnCode":0,"jobId":"9063376","backend":"gizmo","end":"2025-02-11T07:42:46.332Z","start":"2025-02-11T07:42:04.108Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5/call-Uppercase/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:12.686Z","description":"RunningJob","endTime":"2025-02-11T07:42:45.882Z"},{"startTime":"2025-02-11T07:42:45.882Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:42:46.332Z"},{"startTime":"2025-02-11T07:42:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:12.678Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"Pending","endTime":"2025-02-11T07:42:04.108Z"},{"startTime":"2025-02-11T07:42:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:42:12.686Z"},{"startTime":"2025-02-11T07:42:04.108Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:12.677Z"}]}]},"outputs":{"ArrayOperations.first_index":0,"ArrayOperations.processed_nested":[["nested1","nested2"],["nested3","nested4"]],"ArrayOperations.uppercased":["HELLO","WORLD","TEST"],"ArrayOperations.files_localized":true,"ArrayOperations.concat_test_passed":true,"ArrayOperations.last_index":2,"ArrayOperations.file_contents":["Hello...---","...
        is it me you''re ...---","... looking for???---"],"ArrayOperations.flattened":["nested1","nested2","nested3","nested4"],"ArrayOperations.sorted_array":["hello","test","world"],"ArrayOperations.combined_numbers":[1,2,3,4,5,6,7,8,9,10],"ArrayOperations.array_length":3,"ArrayOperations.sum_result":15},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/ArrayOperations/391c6089-ff50-45e5-b745-071a2b115ba5","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:42:54.092Z","start":"2025-02-11T07:41:59.986Z","id":"391c6089-ff50-45e5-b745-071a2b115ba5","inputs":{"input_files":["arrayOperations/data/test1.txt","arrayOperations/data/test2.txt","arrayOperations/data/test3.txt"],"additional_strings":["foo","bar"],"numbers":[1,2,3,4,5],"strings":["hello","world","test"],"nested_arrays":[["nested1","nested2"],["nested3","nested4"]]},"labels":{"cromwell-workflow-id":"cromwell-391c6089-ff50-45e5-b745-071a2b115ba5"},"submission":"2025-02-11T07:38:44.815Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '25138'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"jobId":"9063410","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3158'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"QueuedInCromwell","shardIndex":-1,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4201'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"QueuedInCromwell","shardIndex":-1,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4201'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5435'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"jobId":"9063422","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"jobId":"9063422","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"jobId":"9063422","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:46 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"jobId":"9063422","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:51 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"jobId":"9063422","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:43:56 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/task2_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063422","backend":"gizmo","end":"2025-02-11T07:43:56.334Z","start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:43:22.688Z"},{"startTime":"2025-02-11T07:43:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:22.677Z"},{"startTime":"2025-02-11T07:43:55.526Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:56.334Z"},{"startTime":"2025-02-11T07:43:14.368Z","description":"Pending","endTime":"2025-02-11T07:43:14.368Z"},{"startTime":"2025-02-11T07:43:14.368Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:22.677Z"},{"startTime":"2025-02-11T07:43:22.688Z","description":"RunningJob","endTime":"2025-02-11T07:43:55.526Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:01 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '6374'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/8e247657-6841-4932-a097-4a2283d0f17e/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"jsonTaskOrderTest","workflowProcessingEvents":[{"description":"Finished","cromwellVersion":"87","cromwellId":"cromid-fd06105","timestamp":"2025-02-11T07:43:58.229Z"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:00.055Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow jsonTaskOrderTest {\n  input {\n    String input_json  # JSON
        string used as input for both tasks\n  }\n\n  call Task1 { input: input_json
        = input_json }\n  call Task2 { input: input_json = input_json, previous_output
        = Task1.output_file }\n\n  output {\n    File task1_output = Task1.output_file\n    File
        task2_output = Task2.output_file\n  }\n}\n\ntask Task1 {\n  input {\n    String
        input_json\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task1: ~{input_json}\"
        > task1_output.txt\n    echo \"Task1 completed\" >> task1_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task1_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n\ntask Task2 {\n  input {\n    String input_json\n    File
        previous_output\n  }\n  \n  command <<<\n    echo \"Processing JSON in Task2:
        ~{input_json}\" > task2_output.txt\n    echo \"Task2 completed after Task1\"
        >> task2_output.txt\n    cat ~{previous_output} >> task2_output.txt\n  >>>\n  \n  output
        {\n    File output_file = \"task2_output.txt\"\n  }\n  \n  runtime {\n    cpu:
        1\n    memory: \"2G\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"jsonTaskOrderTest.input_json\":\"I am the text that
        from input.json\"}","workflowUrl":"","labels":"{}"},"calls":{"jsonTaskOrderTest.Task1":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task1: I am the text that from input.json\" > task1_output.txt\necho
        \"Task1 completed\" >> task1_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063410","backend":"gizmo","end":"2025-02-11T07:43:13.332Z","start":"2025-02-11T07:43:02.129Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:02.129Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:02.678Z"},{"startTime":"2025-02-11T07:43:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:12.901Z"},{"endTime":"2025-02-11T07:43:02.687Z","startTime":"2025-02-11T07:43:02.678Z","description":"PreparingJob"},{"startTime":"2025-02-11T07:43:02.129Z","description":"Pending","endTime":"2025-02-11T07:43:02.129Z"},{"startTime":"2025-02-11T07:43:12.901Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:13.332Z"}]}],"jsonTaskOrderTest.Task2":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing JSON in Task2: I am the text that from input.json\" > task2_output.txt\necho
        \"Task2 completed after Task1\" >> task2_output.txt\ncat /redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/inputs/575343790/task1_output.txt
        >> task2_output.txt","shardIndex":-1,"outputs":{"output_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/task2_output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"2
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"previous_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt","input_json":"I
        am the text that from input.json"},"returnCode":0,"jobId":"9063422","backend":"gizmo","end":"2025-02-11T07:43:56.334Z","start":"2025-02-11T07:43:14.368Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:43:22.688Z"},{"startTime":"2025-02-11T07:43:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:22.677Z"},{"startTime":"2025-02-11T07:43:55.526Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:56.334Z"},{"startTime":"2025-02-11T07:43:14.368Z","description":"Pending","endTime":"2025-02-11T07:43:14.368Z"},{"startTime":"2025-02-11T07:43:14.368Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:22.677Z"},{"startTime":"2025-02-11T07:43:22.688Z","description":"RunningJob","endTime":"2025-02-11T07:43:55.526Z"}]}]},"outputs":{"jsonTaskOrderTest.task2_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task2/execution/task2_output.txt","jsonTaskOrderTest.task1_output":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e/call-Task1/execution/task1_output.txt"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/jsonTaskOrderTest/8e247657-6841-4932-a097-4a2283d0f17e","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:43:58.229Z","start":"2025-02-11T07:43:00.056Z","id":"8e247657-6841-4932-a097-4a2283d0f17e","inputs":{"input_json":"I
        am the text that from input.json"},"labels":{"cromwell-workflow-id":"cromwell-8e247657-6841-4932-a097-4a2283d0f17e"},"submission":"2025-02-11T07:38:44.856Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '6889'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/94e90cbc-60db-4e63-81fd-7c3194b544e3/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"globNonmatching","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:43:57.842Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:20.076Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow globNonmatching {\n    call create_files\n    output {\n        Array[File]
        unmatched_files = create_files.unmatched_files\n    }\n}\n\ntask create_files
        {\n    command <<<\n        echo \"Test file\" > test.txt\n    >>>\n    output
        {\n        Array[File] unmatched_files = glob(\"*.log\")\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"globNonmatching.create_files":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globNonmatching/94e90cbc-60db-4e63-81fd-7c3194b544e3/call-create_files/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Test file\" > test.txt","shardIndex":-1,"outputs":{"unmatched_files":[]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063421","backend":"gizmo","end":"2025-02-11T07:43:56.334Z","start":"2025-02-11T07:43:21.119Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globNonmatching/94e90cbc-60db-4e63-81fd-7c3194b544e3/call-create_files/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globNonmatching/94e90cbc-60db-4e63-81fd-7c3194b544e3/call-create_files","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:21.119Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:22.677Z"},{"startTime":"2025-02-11T07:43:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:22.677Z"},{"startTime":"2025-02-11T07:43:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:43:22.692Z"},{"startTime":"2025-02-11T07:43:22.692Z","description":"RunningJob","endTime":"2025-02-11T07:43:55.999Z"},{"startTime":"2025-02-11T07:43:55.999Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:56.334Z"},{"startTime":"2025-02-11T07:43:21.119Z","description":"Pending","endTime":"2025-02-11T07:43:21.119Z"}]}]},"outputs":{"globNonmatching.unmatched_files":[]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globNonmatching/94e90cbc-60db-4e63-81fd-7c3194b544e3","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:43:57.842Z","start":"2025-02-11T07:43:20.076Z","id":"94e90cbc-60db-4e63-81fd-7c3194b544e3","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-94e90cbc-60db-4e63-81fd-7c3194b544e3"},"submission":"2025-02-11T07:38:44.893Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3063'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/880cc3f0-47c5-41c2-b458-006756b3ad52/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"basicGlobTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:42:40.036Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:43:18.820Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow basicGlobTest {\n    call create_files\n    output {\n        Array[File]
        matched_files = create_files.txt_files\n    }\n}\n\ntask create_files {\n    command
        <<<\n        echo \"File 1\" > file1.txt\n        echo \"File 2\" > file2.txt\n    >>>\n    output
        {\n        Array[File] txt_files = glob(\"*.txt\")\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"basicGlobTest.create_files":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"File 1\" > file1.txt\necho \"File 2\" > file2.txt","shardIndex":-1,"outputs":{"txt_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/file1.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/file2.txt"]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063397","backend":"gizmo","end":"2025-02-11T07:43:17.333Z","start":"2025-02-11T07:42:41.080Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:42:42.687Z","description":"RunningJob","endTime":"2025-02-11T07:43:16.681Z"},{"startTime":"2025-02-11T07:42:42.677Z","description":"PreparingJob","endTime":"2025-02-11T07:42:42.687Z"},{"startTime":"2025-02-11T07:42:41.080Z","description":"Pending","endTime":"2025-02-11T07:42:41.080Z"},{"startTime":"2025-02-11T07:42:41.080Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:42:42.677Z"},{"startTime":"2025-02-11T07:43:16.681Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:43:17.333Z"},{"startTime":"2025-02-11T07:42:42.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:42:42.677Z"}]}]},"outputs":{"basicGlobTest.matched_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/file1.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52/call-create_files/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/file2.txt"]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicGlobTest/880cc3f0-47c5-41c2-b458-006756b3ad52","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:43:18.820Z","start":"2025-02-11T07:42:40.036Z","id":"880cc3f0-47c5-41c2-b458-006756b3ad52","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-880cc3f0-47c5-41c2-b458-006756b3ad52"},"submission":"2025-02-11T07:38:44.931Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3813'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"HelloHostname","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:40.095Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This is a test workflow that returns the hostname of the node \n##
        the job is submitted to as a test for the Gizmo backend. \n\n#### WORKFLOW
        DEFINITION\n\nworkflow HelloHostname {\n  call Hostname {\n  }\n\n  output
        {\n    File stdout = Hostname.out\n  }\n\n  parameter_meta {\n    stdout:
        \"hostname of the node the job was submitted to\"\n  }\n}\n\n#### TASK DEFINITIONS\n\ntask
        Hostname {\n  command <<<\n    echo $(hostname)\n  >>>\n\n  output {\n    File
        out = stdout()\n  }\n  \n  runtime {\n    cpu: 1\n    memory: \"1 GB\"\n  }\n\n  parameter_meta
        {\n    out: \"hostname of the node the job was submitted to\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"HelloHostname.Hostname":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname/execution/stdout","backendStatus":"Running","commandLine":"echo
        $(hostname)","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"jobId":"9063484","backend":"gizmo","attempt":1,"start":"2025-02-11T07:43:41.137Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:43:40.095Z","id":"bc4e39b3-7864-4c80-a0ad-d60ecd38d746","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-bc4e39b3-7864-4c80-a0ad-d60ecd38d746"},"submission":"2025-02-11T07:38:44.968Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2390'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"HelloHostname","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:44:19.899Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:43:40.095Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This is a test workflow that returns the hostname of the node \n##
        the job is submitted to as a test for the Gizmo backend. \n\n#### WORKFLOW
        DEFINITION\n\nworkflow HelloHostname {\n  call Hostname {\n  }\n\n  output
        {\n    File stdout = Hostname.out\n  }\n\n  parameter_meta {\n    stdout:
        \"hostname of the node the job was submitted to\"\n  }\n}\n\n#### TASK DEFINITIONS\n\ntask
        Hostname {\n  command <<<\n    echo $(hostname)\n  >>>\n\n  output {\n    File
        out = stdout()\n  }\n  \n  runtime {\n    cpu: 1\n    memory: \"1 GB\"\n  }\n\n  parameter_meta
        {\n    out: \"hostname of the node the job was submitted to\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"HelloHostname.Hostname":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname/execution/stdout","backendStatus":"Done","commandLine":"echo
        $(hostname)","shardIndex":-1,"outputs":{"out":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname/execution/stdout"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063484","backend":"gizmo","end":"2025-02-11T07:44:18.332Z","start":"2025-02-11T07:43:41.137Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:43:41.137Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:43:42.677Z"},{"startTime":"2025-02-11T07:43:42.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:43:42.677Z"},{"startTime":"2025-02-11T07:43:41.137Z","description":"Pending","endTime":"2025-02-11T07:43:41.137Z"},{"startTime":"2025-02-11T07:43:42.677Z","description":"PreparingJob","endTime":"2025-02-11T07:43:42.685Z"},{"startTime":"2025-02-11T07:43:42.685Z","description":"RunningJob","endTime":"2025-02-11T07:44:18.117Z"},{"startTime":"2025-02-11T07:44:18.117Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:44:18.332Z"}]}]},"outputs":{"HelloHostname.stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746/call-Hostname/execution/stdout"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloHostname/bc4e39b3-7864-4c80-a0ad-d60ecd38d746","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:44:19.899Z","start":"2025-02-11T07:43:40.095Z","id":"bc4e39b3-7864-4c80-a0ad-d60ecd38d746","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-bc4e39b3-7864-4c80-a0ad-d60ecd38d746"},"submission":"2025-02-11T07:38:44.968Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3579'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:37 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:42 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:47 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:52 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:44:57 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:02 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:07 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:12 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:17 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:22 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:27 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:32 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:48 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:53 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:45:58 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:03 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:08 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:13 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"submittedFiles":{"workflow":"version 1.0\n\n# Define the structure
        for sampleDetails\nstruct sampleDetails {\n    String experimentType\n    String
        prepMethod\n    String tissueType\n}\n\n# Define the main structure for the
        single sample\nstruct singleSample {\n    String sampleName\n    String aboutSample\n    String
        sampleDescription\n    sampleDetails details  # Use the sampleDetails struct
        here\n}\n\nworkflow testNestedJsonArray {\n  input {\n    String cellNumber\n    Array[singleSample]
        batchOfSamples  # Array of objects representing each sample\n  }\n\n  scatter
        (sample in batchOfSamples) {\n    call processSample {\n      input:\n        sample
        = sample,\n        base_file_name = sample.sampleName \n    }\n  }\n\n  output
        {\n    # Collect all the fields together from each sample into one list\n    Array[File]
        result_allSampleInfo = processSample.allSampleInfo\n  }\n}\n\ntask processSample
        {\n  input {\n    singleSample sample  # Use singleSample type, not Object\n    String
        base_file_name\n  }\n\n  command <<<\n    # Format the sample information
        as a single string\n    allSampleInfo=\"~{sample.sampleName} | ~{sample.aboutSample}
        | ~{sample.sampleDescription} | ~{sample.details.experimentType} | ~{sample.details.prepMethod}
        | ~{sample.details.tissueType}\"\n    \n    # Output the concatenated sample
        info to a file\n    echo \"${allSampleInfo}\" > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output
        {\n    # Read all sample info from the file and output it as an Array of Strings\n    File
        allSampleInfo = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"status":"Submitted","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:18 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2925'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:23 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4085'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"QueuedInCromwell","shardIndex":0,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z"},{"executionStatus":"QueuedInCromwell","shardIndex":1,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z"},{"executionStatus":"QueuedInCromwell","shardIndex":2,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:28 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"QueuedInCromwell","shardIndex":0,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z"},{"executionStatus":"QueuedInCromwell","shardIndex":1,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z"},{"executionStatus":"QueuedInCromwell","shardIndex":2,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:33 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4479'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:38 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8545'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"jobId":"9063635","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"jobId":"9063636","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"jobId":"9063637","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:43 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8677'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"jobId":"9063635","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"jobId":"9063636","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"jobId":"9063637","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8677'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"jobId":"9063635","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"jobId":"9063636","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"jobId":"9063637","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:54 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8677'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"jobId":"9063635","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"jobId":"9063636","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"jobId":"9063637","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:46:59 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8677'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"jobId":"9063635","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"jobId":"9063636","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"jobId":"9063637","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:04 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8677'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"jobId":"9063635","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"jobId":"9063636","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Running","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"jobId":"9063637","backend":"gizmo","attempt":1,"start":"2025-02-11T07:46:24.372Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:09 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '8677'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testNestedJsonArray","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:47:12.310Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:20.266Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# Define the structure for sampleDetails\nstruct sampleDetails {\n    String
        experimentType\n    String prepMethod\n    String tissueType\n}\n\n# Define
        the main structure for the single sample\nstruct singleSample {\n    String
        sampleName\n    String aboutSample\n    String sampleDescription\n    sampleDetails
        details  # Use the sampleDetails struct here\n}\n\nworkflow testNestedJsonArray
        {\n  input {\n    String cellNumber\n    Array[singleSample] batchOfSamples  #
        Array of objects representing each sample\n  }\n\n  scatter (sample in batchOfSamples)
        {\n    call processSample {\n      input:\n        sample = sample,\n        base_file_name
        = sample.sampleName \n    }\n  }\n\n  output {\n    # Collect all the fields
        together from each sample into one list\n    Array[File] result_allSampleInfo
        = processSample.allSampleInfo\n  }\n}\n\ntask processSample {\n  input {\n    singleSample
        sample  # Use singleSample type, not Object\n    String base_file_name\n  }\n\n  command
        <<<\n    # Format the sample information as a single string\n    allSampleInfo=\"~{sample.sampleName}
        | ~{sample.aboutSample} | ~{sample.sampleDescription} | ~{sample.details.experimentType}
        | ~{sample.details.prepMethod} | ~{sample.details.tissueType}\"\n    \n    #
        Output the concatenated sample info to a file\n    echo \"${allSampleInfo}\"
        > ~{base_file_name}.allSampleInfo.txt\n  >>>\n\n  output {\n    # Read all
        sample info from the file and output it as an Array of Strings\n    File allSampleInfo
        = \"${base_file_name}.allSampleInfo.txt\"\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"testNestedJsonArray.batchOfSamples\":[{\"aboutSample\":\"This
        is sample 1\",\"details\":{\"experimentType\":\"RNA-Seq\",\"prepMethod\":\"TruSeq\",\"tissueType\":\"blood\"},\"sampleDescription\":\"Description
        of sample 1: A detailed description of the first sample.\",\"sampleName\":\"Sample1\"},{\"aboutSample\":\"This
        is sample 2\",\"details\":{\"experimentType\":\"DNA-Seq\",\"prepMethod\":\"Nextera\",\"tissueType\":\"tissue
        biopsy\"},\"sampleDescription\":\"Description of sample 2: A detailed description
        of the second sample.\",\"sampleName\":\"Sample2\"},{\"aboutSample\":\"This
        is sample 3\",\"details\":{\"experimentType\":\"ChIP-Seq\",\"prepMethod\":\"Epigenome\",\"tissueType\":\"brain\"},\"sampleDescription\":\"Description
        of sample 3: A detailed description of the third sample.\",\"sampleName\":\"Sample3\"}],\"testNestedJsonArray.cellNumber\":\"10000\"}","workflowUrl":"","labels":"{}"},"calls":{"testNestedJsonArray.processSample":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stdout","backendStatus":"Done","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample1
        | This is sample 1 | Description of sample 1: A detailed description of the
        first sample. | RNA-Seq | TruSeq | blood\"\n\n# Output the concatenated sample
        info to a file\necho \"${allSampleInfo}\" > Sample1.allSampleInfo.txt","shardIndex":0,"outputs":{"allSampleInfo":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/Sample1.allSampleInfo.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample1","sample":{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}}},"returnCode":0,"jobId":"9063635","backend":"gizmo","start":"2025-02-11T07:46:24.372Z","end":"2025-02-11T07:47:09.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:46:32.693Z","description":"RunningJob","endTime":"2025-02-11T07:47:09.274Z"},{"startTime":"2025-02-11T07:46:24.372Z","description":"Pending","endTime":"2025-02-11T07:46:24.372Z"},{"startTime":"2025-02-11T07:46:24.372Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:46:32.677Z"},{"startTime":"2025-02-11T07:46:32.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:46:32.677Z"},{"startTime":"2025-02-11T07:47:09.274Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:09.332Z"},{"startTime":"2025-02-11T07:46:32.677Z","description":"PreparingJob","endTime":"2025-02-11T07:46:32.693Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stdout","backendStatus":"Done","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample2
        | This is sample 2 | Description of sample 2: A detailed description of the
        second sample. | DNA-Seq | Nextera | tissue biopsy\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample2.allSampleInfo.txt","shardIndex":1,"outputs":{"allSampleInfo":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/Sample2.allSampleInfo.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample2","sample":{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}}},"returnCode":0,"jobId":"9063636","backend":"gizmo","start":"2025-02-11T07:46:24.372Z","end":"2025-02-11T07:47:09.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:46:32.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:46:32.678Z"},{"startTime":"2025-02-11T07:46:24.372Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:46:32.677Z"},{"startTime":"2025-02-11T07:47:09.154Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:09.332Z"},{"startTime":"2025-02-11T07:46:32.695Z","description":"RunningJob","endTime":"2025-02-11T07:47:09.154Z"},{"startTime":"2025-02-11T07:46:32.678Z","description":"PreparingJob","endTime":"2025-02-11T07:46:32.695Z"},{"startTime":"2025-02-11T07:46:24.372Z","description":"Pending","endTime":"2025-02-11T07:46:24.372Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stdout","backendStatus":"Done","commandLine":"#
        Format the sample information as a single string\nallSampleInfo=\"Sample3
        | This is sample 3 | Description of sample 3: A detailed description of the
        third sample. | ChIP-Seq | Epigenome | brain\"\n\n# Output the concatenated
        sample info to a file\necho \"${allSampleInfo}\" > Sample3.allSampleInfo.txt","shardIndex":2,"outputs":{"allSampleInfo":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/Sample3.allSampleInfo.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"base_file_name":"Sample3","sample":{"aboutSample":"This
        is sample 3","sampleName":"Sample3","sampleDescription":"Description of sample
        3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}},"returnCode":0,"jobId":"9063637","backend":"gizmo","start":"2025-02-11T07:46:24.372Z","end":"2025-02-11T07:47:08.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:46:32.678Z","description":"PreparingJob","endTime":"2025-02-11T07:46:32.698Z"},{"startTime":"2025-02-11T07:46:24.372Z","description":"Pending","endTime":"2025-02-11T07:46:24.372Z"},{"startTime":"2025-02-11T07:46:24.372Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:46:32.677Z"},{"startTime":"2025-02-11T07:46:32.698Z","description":"RunningJob","endTime":"2025-02-11T07:47:07.895Z"},{"startTime":"2025-02-11T07:46:32.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:46:32.678Z"},{"startTime":"2025-02-11T07:47:07.895Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:08.332Z"}]}]},"outputs":{"testNestedJsonArray.result_allSampleInfo":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-0/execution/Sample1.allSampleInfo.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-1/execution/Sample2.allSampleInfo.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8/call-processSample/shard-2/execution/Sample3.allSampleInfo.txt"]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testNestedJsonArray/cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:47:12.310Z","start":"2025-02-11T07:46:20.266Z","id":"cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8","inputs":{"batchOfSamples":[{"aboutSample":"This
        is sample 1","sampleName":"Sample1","sampleDescription":"Description of sample
        1: A detailed description of the first sample.","details":{"prepMethod":"TruSeq","experimentType":"RNA-Seq","tissueType":"blood"}},{"aboutSample":"This
        is sample 2","sampleName":"Sample2","sampleDescription":"Description of sample
        2: A detailed description of the second sample.","details":{"prepMethod":"Nextera","experimentType":"DNA-Seq","tissueType":"tissue
        biopsy"}},{"aboutSample":"This is sample 3","sampleName":"Sample3","sampleDescription":"Description
        of sample 3: A detailed description of the third sample.","details":{"prepMethod":"Epigenome","experimentType":"ChIP-Seq","tissueType":"brain"}}],"cellNumber":"10000"},"labels":{"cromwell-workflow-id":"cromwell-cd7ae742-ac05-44bd-9fb4-dfcdcd9e45c8"},"submission":"2025-02-11T07:38:45.011Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:14 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '12469'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2"}],"conditional_example.run_qc_report":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.459Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:19 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7747'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"jobId":"9063750","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"jobId":"9063749","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2"}],"conditional_example.run_qc_report":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"jobId":"9063751","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.459Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:24 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7879'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"jobId":"9063750","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"jobId":"9063749","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2"}],"conditional_example.run_qc_report":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"jobId":"9063751","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.459Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:29 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7879'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"jobId":"9063750","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"jobId":"9063749","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2"}],"conditional_example.run_qc_report":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"jobId":"9063751","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.459Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:34 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7879'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"jobId":"9063750","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"jobId":"9063749","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2"}],"conditional_example.run_qc_report":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"jobId":"9063751","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.459Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:39 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7879'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"jobId":"9063750","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"jobId":"9063749","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2"}],"conditional_example.run_qc_report":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"jobId":"9063751","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.459Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:44 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7879'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"jobId":"9063750","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:06.460Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0"},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:49 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '9841'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:47:55 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '10740'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:00 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '10740'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"QueuedInCromwell","shardIndex":-1,"backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:05 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '10894'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:10 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11915'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"jobId":"9063811","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:15 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11959'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"jobId":"9063811","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:20 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11959'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"jobId":"9063811","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11959'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"jobId":"9063811","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11959'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Running","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"jobId":"9063811","backend":"gizmo","attempt":1,"start":"2025-02-11T07:47:57.458Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize"}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:36 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '11959'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"outputs":{"summary":"Multiple high-quality samples processed\nNumber
        of samples processed: 2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"returnCode":0,"jobId":"9063811","backend":"gizmo","start":"2025-02-11T07:47:57.458Z","end":"2025-02-11T07:48:35.331Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:48:02.677Z","description":"PreparingJob","endTime":"2025-02-11T07:48:02.687Z"},{"startTime":"2025-02-11T07:47:57.458Z","description":"Pending","endTime":"2025-02-11T07:47:57.459Z"},{"startTime":"2025-02-11T07:48:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:48:34.966Z"},{"startTime":"2025-02-11T07:48:34.966Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:48:35.331Z"},{"startTime":"2025-02-11T07:48:02.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:48:02.677Z"},{"startTime":"2025-02-11T07:47:57.459Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:48:02.677Z"}]}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:41 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '12875'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"conditional_example","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:47:00.307Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:48:38.260Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This workflow demonstrates the usage of conditional statements in
        WDL\n## by selectively processing samples based on their properties\n\nstruct
        SampleInfo {\n    String name\n    Float quality_score\n    String type\n}\n\nworkflow
        conditional_example {\n    input {\n        Array[SampleInfo] samples\n        Float
        quality_threshold\n    }\n\n    # Demonstrate if statement in scatter\n    scatter
        (sample in samples) {\n        if (sample.quality_score >= quality_threshold)
        {\n            call process_high_quality {\n                input:\n                    sample
        = sample\n            }\n        }\n    }\n\n    # Create string arrays for
        the QC report\n    scatter (sample in samples) {\n        String sample_line
        = \"~{sample.name},~{sample.type},~{sample.quality_score}\"\n    }\n\n    #
        Demonstrate single conditional task\n    call run_qc_report {\n        input:\n            sample_lines
        = sample_line\n    }\n\n    # Calculate number of high quality samples\n    Int
        num_high_quality = length(select_all(process_high_quality.message))\n\n    #
        Demonstrate separate conditional blocks (WDL 1.0 approach instead of if/else)\n    Boolean
        has_multiple_samples = num_high_quality > 1\n    \n    if (has_multiple_samples)
        {\n        call summarize {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Multiple
        high-quality samples processed\"\n        }\n    }\n\n    if (!has_multiple_samples)
        {\n        call summarize as summarize_few {\n            input:\n                messages
        = select_all(process_high_quality.message),\n                report = \"Few
        or no high-quality samples found\"\n        }\n    }\n\n    output {\n        String
        final_summary = select_first([summarize.summary, summarize_few.summary])\n        File
        qc_report = run_qc_report.report_csv\n    }\n}\n\ntask process_high_quality
        {\n    input {\n        SampleInfo sample\n    }\n\n    command <<<\n        echo
        \"Processing high quality ~{sample.type} sample ~{sample.name} (Q=~{sample.quality_score})\"\n    >>>\n\n    output
        {\n        String message = read_string(stdout())\n    }\n\n    runtime {\n        docker:
        \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask run_qc_report {\n    input {\n        Array[String]
        sample_lines\n    }\n\n    command <<<\n        echo \"Quality Score Summary:\"\n        echo
        \"Sample Name,Type,Quality Score\" > report.csv\n        ~{sep=\"\\n\" sample_lines}
        >> report.csv\n        cat report.csv\n    >>>\n\n    output {\n        String
        report = read_string(stdout())\n        File report_csv = \"report.csv\"\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n\ntask summarize
        {\n    input {\n        Array[String] messages\n        String report\n    }\n\n    command
        <<<\n        echo \"~{report}\"\n        echo \"Number of samples processed:
        ~{length(messages)}\"\n    >>>\n\n    output {\n        String summary = read_string(stdout())\n    }\n\n    runtime
        {\n        docker: \"ubuntu:noble-20241118.1\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"conditional_example.quality_threshold\":90.0,\"conditional_example.samples\":[{\"name\":\"sample1\",\"quality_score\":95.5,\"type\":\"normal\"},{\"name\":\"sample2\",\"quality_score\":85.3,\"type\":\"tumor\"},{\"name\":\"sample3\",\"quality_score\":92.1,\"type\":\"normal\"}]}","workflowUrl":"","labels":"{}"},"calls":{"conditional_example.summarize":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Multiple high-quality samples processed\"\necho \"Number of samples processed:
        2\"","shardIndex":-1,"outputs":{"summary":"Multiple high-quality samples processed\nNumber
        of samples processed: 2"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"messages":["Processing
        high quality normal sample sample1 (Q=95.5)","Processing high quality normal
        sample sample3 (Q=92.1)"],"report":"Multiple high-quality samples processed"},"returnCode":0,"jobId":"9063811","backend":"gizmo","start":"2025-02-11T07:47:57.458Z","end":"2025-02-11T07:48:35.331Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-summarize","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:48:02.677Z","description":"PreparingJob","endTime":"2025-02-11T07:48:02.687Z"},{"startTime":"2025-02-11T07:47:57.458Z","description":"Pending","endTime":"2025-02-11T07:47:57.459Z"},{"startTime":"2025-02-11T07:48:02.687Z","description":"RunningJob","endTime":"2025-02-11T07:48:34.966Z"},{"startTime":"2025-02-11T07:48:34.966Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:48:35.331Z"},{"startTime":"2025-02-11T07:48:02.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:48:02.677Z"},{"startTime":"2025-02-11T07:47:57.459Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:48:02.677Z"}]}],"conditional_example.process_high_quality":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample1 (Q=95.5)\"","shardIndex":0,"outputs":{"message":"Processing
        high quality normal sample sample1 (Q=95.5)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":95.5,"name":"sample1","type":"normal"}},"returnCode":0,"jobId":"9063750","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:49.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-0","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.696Z","description":"RunningJob","endTime":"2025-02-11T07:47:48.427Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:48.427Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:49.332Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.696Z"}]},{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Processing high quality normal sample sample3 (Q=92.1)\"","shardIndex":2,"outputs":{"message":"Processing
        high quality normal sample sample3 (Q=92.1)"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample":{"quality_score":92.1,"name":"sample3","type":"normal"}},"returnCode":0,"jobId":"9063749","backend":"gizmo","start":"2025-02-11T07:47:06.460Z","end":"2025-02-11T07:47:44.332Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-process_high_quality/shard-2","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:12.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:43.608Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:43.608Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:44.332Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.689Z"},{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.677Z"}]}],"conditional_example.run_qc_report":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Quality Score Summary:\"\necho \"Sample Name,Type,Quality Score\" > report.csv\nsample1,normal,95.5\nsample2,tumor,85.3\nsample3,normal,92.1
        >> report.csv\ncat report.csv","shardIndex":-1,"outputs":{"report":"Quality
        Score Summary:\nSample Name,Type,Quality Score","report_csv":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:noble-20241118.1","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"sample_lines":["sample1,normal,95.5","sample2,tumor,85.3","sample3,normal,92.1"]},"returnCode":0,"jobId":"9063751","backend":"gizmo","start":"2025-02-11T07:47:06.459Z","end":"2025-02-11T07:47:45.334Z","dockerImageUsed":"ubuntu@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:12.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:12.678Z"},{"startTime":"2025-02-11T07:47:12.678Z","description":"PreparingJob","endTime":"2025-02-11T07:47:12.699Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"Pending","endTime":"2025-02-11T07:47:06.460Z"},{"startTime":"2025-02-11T07:47:44.587Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:45.334Z"},{"startTime":"2025-02-11T07:47:06.460Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:12.677Z"},{"startTime":"2025-02-11T07:47:12.699Z","description":"RunningJob","endTime":"2025-02-11T07:47:44.587Z"}]}]},"outputs":{"conditional_example.qc_report":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a/call-run_qc_report/execution/report.csv","conditional_example.final_summary":"Multiple
        high-quality samples processed\nNumber of samples processed: 2"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/conditional_example/df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:48:38.260Z","start":"2025-02-11T07:47:00.307Z","id":"df202fe2-5d3e-4fdd-bb8a-ea8a7753063a","inputs":{"quality_threshold":90.0,"samples":[{"quality_score":95.5,"name":"sample1","type":"normal"},{"quality_score":85.3,"name":"sample2","type":"tumor"},{"quality_score":92.1,"name":"sample3","type":"normal"}]},"labels":{"cromwell-workflow-id":"cromwell-df202fe2-5d3e-4fdd-bb8a-ea8a7753063a"},"submission":"2025-02-11T07:38:45.056Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:46 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '13322'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/93e874b6-7c01-4466-8dc7-fd7bdc3fc1d1/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:45:00.185Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:45:00.200Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n# This workflow takes a tab separated file where each row is a set of
        data to be used in each \n# of the independent scattered task series that
        you have as your workflow process.  This file \n# will, for example, have
        column names `sampleName`, `bamLocation`, and `bedlocation`.  This\n# allows
        you to know that regardless of the order of the columns in your batch file,
        the correct\n# inputs will be used for the tasks you define.  \nworkflow parseBatchFile
        {\n  input {\n  File batchFile\n  }\n    Array[Object] batchInfo = read_objects(batchFile)\n  scatter
        (job in batchInfo){\n    String sampleName = job.sampleName\n    File bamFile
        = job.bamLocation\n    File bedFile = job.bedLocation\n\n    ## INSERT YOUR
        WORKFLOW TO RUN PER LINE IN YOUR BATCH FILE HERE!!!!\n    call test {\n        input:
        in1=sampleName, in2=bamFile, in3=bedFile\n    }\n\n  }  # End Scatter over
        the batch file\n# Outputs that will be retained when execution is complete\n  output
        {\n    Array[File] outputArray = test.item_out\n    }\n# End workflow\n}\n\n####
        TASK DEFINITIONS\n# echo some text to stdout, treats files as strings just
        to echo them as a dummy example\ntask test {\n  input {\n    String in1\n    String
        in2\n    String in3\n  }\n    command {\n    echo ~{in1}\n    echo ~{in2}\n    echo
        ~{in3}\n    }\n    output {\n        File item_out = stdout()\n    }\n}","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"actualWorkflowLanguage":"WDL","status":"Failed","failures":[{"causedBy":[{"causedBy":[],"message":"Required
        workflow input ''parseBatchFile.batchFile'' not specified"}],"message":"Workflow
        input processing failed"}],"end":"2025-02-11T07:45:00.200Z","start":"2025-02-11T07:45:00.186Z","id":"93e874b6-7c01-4466-8dc7-fd7bdc3fc1d1","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-93e874b6-7c01-4466-8dc7-fd7bdc3fc1d1"},"submission":"2025-02-11T07:38:45.131Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:51 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '2382'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/9fe23458-f2b2-4bd1-886f-0811a8c22267/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"globSubdir","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:45:20.205Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:45:57.970Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\nworkflow globSubdir {\n    call create_nested_files\n    output {\n        Array[File]
        matched_files = flatten([create_nested_files.matched_files_top, create_nested_files.matched_files_nested])\n    }\n}\n\ntask
        create_nested_files {\n    command <<<\n        mkdir -p subdir/nested\n        echo
        \"Hello\" > subdir/nested/file1.txt\n        echo \"World\" > subdir/file2.txt\n    >>>\n    output
        {\n        Array[File] matched_files_top = glob(\"subdir/*.txt\")\n        Array[File]
        matched_files_nested = glob(\"subdir/**/*.txt\")\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"globSubdir.create_nested_files":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files/execution/stdout","backendStatus":"Done","commandLine":"mkdir
        -p subdir/nested\necho \"Hello\" > subdir/nested/file1.txt\necho \"World\"
        > subdir/file2.txt","shardIndex":-1,"outputs":{"matched_files_top":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files/execution/glob-ee3a9c1c6860f417d1e9ff1a72d2b62d/file2.txt"],"matched_files_nested":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files/execution/glob-4c0cd9dc6b12aa01233bbc214341aae1/file1.txt"]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063618","backend":"gizmo","end":"2025-02-11T07:45:56.333Z","start":"2025-02-11T07:45:21.251Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:45:22.688Z","description":"RunningJob","endTime":"2025-02-11T07:45:55.498Z"},{"startTime":"2025-02-11T07:45:21.251Z","description":"Pending","endTime":"2025-02-11T07:45:21.251Z"},{"startTime":"2025-02-11T07:45:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:45:22.677Z"},{"startTime":"2025-02-11T07:45:21.251Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:45:22.677Z"},{"startTime":"2025-02-11T07:45:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:45:22.688Z"},{"startTime":"2025-02-11T07:45:55.498Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:45:56.333Z"}]}]},"outputs":{"globSubdir.matched_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files/execution/glob-ee3a9c1c6860f417d1e9ff1a72d2b62d/file2.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267/call-create_nested_files/execution/glob-4c0cd9dc6b12aa01233bbc214341aae1/file1.txt"]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/globSubdir/9fe23458-f2b2-4bd1-886f-0811a8c22267","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:45:57.970Z","start":"2025-02-11T07:45:20.206Z","id":"9fe23458-f2b2-4bd1-886f-0811a8c22267","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-9fe23458-f2b2-4bd1-886f-0811a8c22267"},"submission":"2025-02-11T07:38:45.169Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:48:56 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '4125'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/b7b9ea41-2e6f-48cb-947a-92c99ece53bd/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:46:00.256Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:00.246Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This is a test workflow that fails against womtool.\n## From https://github.com/broadinstitute/cromwell\n\n####
        WORKFLOW DEFINITION\n\nworkflow oops {\n  call oopsie\n}\n\n#### TASK DEFINITIONS\n\ntask
        oopsie {\n  input {\n    String str\n  }\n  command { echo ${str} }\n  runtime
        { docker: docker_image }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{},"outputs":{},"actualWorkflowLanguage":"WDL","status":"Failed","failures":[{"causedBy":[{"causedBy":[],"message":"Failed
        to process task definition ''oopsie'' (reason 1 of 1): Cannot lookup value
        ''docker_image'', it is never declared. Available values are: [''str'']"}],"message":"Workflow
        input processing failed"}],"end":"2025-02-11T07:46:00.255Z","start":"2025-02-11T07:46:00.246Z","id":"b7b9ea41-2e6f-48cb-947a-92c99ece53bd","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-b7b9ea41-2e6f-48cb-947a-92c99ece53bd"},"submission":"2025-02-11T07:38:45.209Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:01 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '1422'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/15114e63-02d5-4bbe-88c7-1a6c78077b92/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"emptyGlobTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:44:00.117Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:44:41.960Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow emptyGlobTest {\n    call create_empty_directory\n\n    output
        {\n        Array[File] no_files = create_empty_directory.no_files\n    }\n}\n\ntask
        create_empty_directory {\n    command {\n        mkdir empty_dir\n    }\n    output
        {\n        Array[File] no_files = glob(\"empty_dir/*.txt\")\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"emptyGlobTest.create_empty_directory":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/emptyGlobTest/15114e63-02d5-4bbe-88c7-1a6c78077b92/call-create_empty_directory/execution/stdout","backendStatus":"Done","commandLine":"mkdir
        empty_dir","shardIndex":-1,"outputs":{"no_files":[]},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063538","backend":"gizmo","end":"2025-02-11T07:44:40.332Z","start":"2025-02-11T07:44:01.159Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/emptyGlobTest/15114e63-02d5-4bbe-88c7-1a6c78077b92/call-create_empty_directory/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/emptyGlobTest/15114e63-02d5-4bbe-88c7-1a6c78077b92/call-create_empty_directory","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:44:01.159Z","description":"Pending","endTime":"2025-02-11T07:44:01.159Z"},{"startTime":"2025-02-11T07:44:02.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:44:02.677Z"},{"startTime":"2025-02-11T07:44:39.879Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:44:40.332Z"},{"startTime":"2025-02-11T07:44:02.677Z","description":"PreparingJob","endTime":"2025-02-11T07:44:02.686Z"},{"startTime":"2025-02-11T07:44:02.686Z","description":"RunningJob","endTime":"2025-02-11T07:44:39.879Z"},{"startTime":"2025-02-11T07:44:01.159Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:44:02.677Z"}]}]},"outputs":{"emptyGlobTest.no_files":[]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/emptyGlobTest/15114e63-02d5-4bbe-88c7-1a6c78077b92","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:44:41.960Z","start":"2025-02-11T07:44:00.117Z","id":"15114e63-02d5-4bbe-88c7-1a6c78077b92","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-15114e63-02d5-4bbe-88c7-1a6c78077b92"},"submission":"2025-02-11T07:38:45.247Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:06 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3062'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/16977ca9-7af2-4fb4-ac08-727402a6ea23/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"WildcardsandConditions","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:45:05.050Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:44:20.138Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow WildcardsandConditions {\n    input {\n        String prefix  #
        Required input for the file prefix (no default value)\n    }\n\n    call wildcard_and_conditions_test
        {\n        input:\n            prefix = prefix  # Explicitly pass the workflow
        input to the task\n    }\n\n    output {\n        Array[File] txt_files =
        wildcard_and_conditions_test.txt_files\n        String conditional_result
        = wildcard_and_conditions_test.conditional_output\n    }\n}\n\ntask wildcard_and_conditions_test
        {\n    input {\n        String prefix  # Required input for file creation\n        Boolean
        create_extra_file = true  # Default value for conditional logic\n    }\n\n    command
        <<<\n        # Create multiple .txt files to test wildcard resolution\n        for
        i in {1..3}; do\n            echo \"File content $i\" > \"~{prefix}_$i.txt\"\n        done\n\n        #
        Create an extra file conditionally\n        if [[ ~{create_extra_file} ==
        \"true\" ]]; then\n            echo \"Extra file content\" > ~{prefix}_extra.txt\n        fi\n\n        #
        Parse inputs directly in the command\n        echo \"Parsed prefix: ~{prefix}\"
        > parsed_output.txt\n    >>>\n\n    output {\n        Array[File] txt_files
        = glob(\"*.txt\")  # Test wildcard resolution\n        String conditional_output
        = read_string(\"parsed_output.txt\")  # Verify input parsing\n    }\n\n    runtime
        {\n        docker: \"ubuntu:20.04\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"WildcardsandConditions.prefix\":\"testfile\"}","workflowUrl":"","labels":"{}"},"calls":{"WildcardsandConditions.wildcard_and_conditions_test":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/stdout","backendStatus":"Done","commandLine":"#
        Create multiple .txt files to test wildcard resolution\nfor i in {1..3}; do\n    echo
        \"File content $i\" > \"testfile_$i.txt\"\ndone\n\n# Create an extra file
        conditionally\nif [[ true == \"true\" ]]; then\n    echo \"Extra file content\"
        > testfile_extra.txt\nfi\n\n# Parse inputs directly in the command\necho \"Parsed
        prefix: testfile\" > parsed_output.txt","shardIndex":-1,"outputs":{"txt_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/parsed_output.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_1.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_2.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_3.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_extra.txt"],"conditional_output":"Parsed
        prefix: testfile"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"prefix":"testfile","create_extra_file":true},"returnCode":0,"jobId":"9063596","backend":"gizmo","start":"2025-02-11T07:44:22.209Z","end":"2025-02-11T07:45:03.337Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:44:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:44:22.689Z"},{"startTime":"2025-02-11T07:45:02.865Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:45:03.337Z"},{"startTime":"2025-02-11T07:44:22.209Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:44:22.677Z"},{"startTime":"2025-02-11T07:44:22.689Z","description":"RunningJob","endTime":"2025-02-11T07:45:02.865Z"},{"startTime":"2025-02-11T07:44:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:44:22.677Z"},{"startTime":"2025-02-11T07:44:22.209Z","description":"Pending","endTime":"2025-02-11T07:44:22.209Z"}]}]},"outputs":{"WildcardsandConditions.conditional_result":"Parsed
        prefix: testfile","WildcardsandConditions.txt_files":["/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/parsed_output.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_1.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_2.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_3.txt","/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23/call-wildcard_and_conditions_test/execution/glob-ef5df339533c1334f081dc8cc75ee4f3/testfile_extra.txt"]},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/WildcardsandConditions/16977ca9-7af2-4fb4-ac08-727402a6ea23","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:45:05.050Z","start":"2025-02-11T07:44:20.139Z","id":"16977ca9-7af2-4fb4-ac08-727402a6ea23","inputs":{"WildcardsandConditions.wildcard_and_conditions_test.create_extra_file":true,"prefix":"testfile"},"labels":{"cromwell-workflow-id":"cromwell-16977ca9-7af2-4fb4-ac08-727402a6ea23"},"submission":"2025-02-11T07:38:45.285Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:11 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '7155'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/af275974-bfe6-4151-b7ae-f325518291c6/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"testFileoperations","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:46:22.070Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:45:40.226Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\nworkflow testFileoperations {\n    call file_operations\n\n    output
        {\n        File created_file1 = file_operations.created_file1\n        File
        moved_file = file_operations.moved_file\n        File renamed_file = file_operations.renamed_file\n    }\n}\n\ntask
        file_operations {\n    command <<<\n        # Create three different files\n        echo
        \"This is the first created file.\" > file1.txt\n        echo \"This is the
        second file that will be moved.\" > file2.txt\n        echo \"This is the
        third file that will be renamed.\" > file3.txt\n        \n        # Move the
        second file to a new directory\n        mkdir -p output_dir\n        mv file2.txt
        output_dir/\n        \n        # Rename the third file\n        mv file3.txt
        file3_renamed.txt\n    >>>\n\n    output {\n        # Output the actual existing
        files\n        File created_file1 = \"file1.txt\"                  # The first
        file remains unchanged\n        File moved_file = \"output_dir/file2.txt\"          #
        The second file after being moved\n        File renamed_file = \"file3_renamed.txt\"           #
        The third file after being renamed\n    }\n\n    runtime {\n        docker:
        \"ubuntu:20.04\"\n    }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"testFileoperations.file_operations":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/stdout","backendStatus":"Done","commandLine":"#
        Create three different files\necho \"This is the first created file.\" > file1.txt\necho
        \"This is the second file that will be moved.\" > file2.txt\necho \"This is
        the third file that will be renamed.\" > file3.txt\n\n# Move the second file
        to a new directory\nmkdir -p output_dir\nmv file2.txt output_dir/\n\n# Rename
        the third file\nmv file3.txt file3_renamed.txt","shardIndex":-1,"outputs":{"renamed_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/file3_renamed.txt","moved_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/output_dir/file2.txt","created_file1":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/file1.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063619","backend":"gizmo","start":"2025-02-11T07:45:41.269Z","end":"2025-02-11T07:46:20.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:46:19.399Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:46:20.332Z"},{"startTime":"2025-02-11T07:45:41.269Z","description":"Pending","endTime":"2025-02-11T07:45:41.270Z"},{"startTime":"2025-02-11T07:45:42.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:45:42.677Z"},{"startTime":"2025-02-11T07:45:42.689Z","description":"RunningJob","endTime":"2025-02-11T07:46:19.399Z"},{"startTime":"2025-02-11T07:45:41.270Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:45:42.677Z"},{"startTime":"2025-02-11T07:45:42.677Z","description":"PreparingJob","endTime":"2025-02-11T07:45:42.689Z"}]}]},"outputs":{"testFileoperations.created_file1":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/file1.txt","testFileoperations.renamed_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/file3_renamed.txt","testFileoperations.moved_file":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6/call-file_operations/execution/output_dir/file2.txt"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/testFileoperations/af275974-bfe6-4151-b7ae-f325518291c6","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:46:22.070Z","start":"2025-02-11T07:45:40.226Z","id":"af275974-bfe6-4151-b7ae-f325518291c6","inputs":{},"labels":{"cromwell-workflow-id":"cromwell-af275974-bfe6-4151-b7ae-f325518291c6"},"submission":"2025-02-11T07:38:45.322Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:16 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '5466'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/1b465586-5f57-417d-aad2-b24ce6310f70/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"basicTaskTest","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:44:40.167Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:45:16.910Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n\n# The basicTaskTest workflow calls a task named simpleTask, which takes
        a string input and writes it to a file called output.txt. It demonstrates
        a basic execution of a task with file output.\n\n# This tests basic task execution,
        input handling, and file output functionality. It ensures that a task can
        successfully take an input and generate an output.\n\nworkflow basicTaskTest
        {\n  input {\n    String text = \"Hello, World!\"\n  }\n\n  call simpleTask
        {\n    input:\n      message = text\n  }\n}\n\ntask simpleTask {\n  input
        {\n    String message\n  }\n\n  command <<<\n    echo \"~{message}\" > output.txt\n  >>>\n\n  output
        {\n    File outputFile = \"output.txt\"\n  }\n\n  runtime {\n    docker: \"ubuntu:20.04\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{}","workflowUrl":"","labels":"{}"},"calls":{"basicTaskTest.simpleTask":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicTaskTest/1b465586-5f57-417d-aad2-b24ce6310f70/call-simpleTask/execution/stdout","backendStatus":"Done","commandLine":"echo
        \"Hello, World!\" > output.txt","shardIndex":-1,"outputs":{"outputFile":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicTaskTest/1b465586-5f57-417d-aad2-b24ce6310f70/call-simpleTask/execution/output.txt"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1.953125
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"message":"Hello,
        World!"},"returnCode":0,"jobId":"9063597","backend":"gizmo","start":"2025-02-11T07:44:42.229Z","end":"2025-02-11T07:45:16.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicTaskTest/1b465586-5f57-417d-aad2-b24ce6310f70/call-simpleTask/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicTaskTest/1b465586-5f57-417d-aad2-b24ce6310f70/call-simpleTask","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:44:42.690Z","description":"RunningJob","endTime":"2025-02-11T07:45:15.404Z"},{"startTime":"2025-02-11T07:44:42.229Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:44:42.677Z"},{"startTime":"2025-02-11T07:44:42.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:44:42.678Z"},{"startTime":"2025-02-11T07:44:42.229Z","description":"Pending","endTime":"2025-02-11T07:44:42.229Z"},{"startTime":"2025-02-11T07:44:42.678Z","description":"PreparingJob","endTime":"2025-02-11T07:44:42.690Z"},{"startTime":"2025-02-11T07:45:15.404Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:45:16.332Z"}]}]},"outputs":{"basicTaskTest.simpleTask.outputFile":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicTaskTest/1b465586-5f57-417d-aad2-b24ce6310f70/call-simpleTask/execution/output.txt"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/basicTaskTest/1b465586-5f57-417d-aad2-b24ce6310f70","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:45:16.910Z","start":"2025-02-11T07:44:40.167Z","id":"1b465586-5f57-417d-aad2-b24ce6310f70","inputs":{"text":"Hello,
        World!"},"labels":{"cromwell-workflow-id":"cromwell-1b465586-5f57-417d-aad2-b24ce6310f70"},"submission":"2025-02-11T07:38:45.359Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:21 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '3919'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/d958d760-e7ff-4d55-9b74-90113c0dc1d7/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"HelloDockerHostname","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:40.286Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This is a test workflow that returns the Docker image name and tag\n##
        and measures execution time of the Hostname task.\n\n#### WORKFLOW DEFINITION\n\nworkflow
        HelloDockerHostname {\n  input {\n    String docker_image = \"ubuntu:20.04\"  #
        Default value but can be overridden\n  }\n\n  call GetStartTime\n\n  call
        Hostname {\n    input:\n      expected_image = docker_image,\n      start_time
        = GetStartTime.timestamp  # Add dependency on start time\n  }\n\n  call GetEndTime
        {\n    input:\n      hostname_done = Hostname.out  # Add dependency on Hostname
        completion\n  }\n\n  call ValidateExecutionTime {\n    input:\n      start_time
        = GetStartTime.timestamp,\n      end_time = GetEndTime.timestamp\n  }\n\n  output
        {\n    File stdout = Hostname.out\n    Float execution_time_seconds = ValidateExecutionTime.duration_seconds\n    Boolean
        within_time_limit = ValidateExecutionTime.within_limit\n  }\n\n  parameter_meta
        {\n    docker_image: \"Docker image to run the task in (e.g. ubuntu:latest)\"\n  }\n}\n\n####
        TASK DEFINITIONS\n\ntask GetStartTime {\n  command <<<\n    date +%s.%N\n  >>>\n\n  output
        {\n    Float timestamp = read_float(stdout())\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n    cpu: 1\n    memory: \"1 GB\"\n  }\n}\n\ntask GetEndTime
        {\n  input {\n    File hostname_done  # Add dependency on Hostname completion\n  }\n\n  command
        <<<\n    date +%s.%N\n  >>>\n\n  output {\n    Float timestamp = read_float(stdout())\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n    cpu: 1\n    memory: \"1 GB\"\n  }\n}\n\ntask
        ValidateExecutionTime {\n  input {\n    Float start_time\n    Float end_time\n  }\n\n  command
        <<<\n    # Calculate duration using awk for floating point arithmetic\n    duration=$(awk
        \"BEGIN {print ~{end_time} - ~{start_time}}\")\n    echo \"$duration\" > duration.txt\n    \n    #
        Check if duration is less than 120 seconds (2 minutes)\n    awk -v dur=\"$duration\"
        ''BEGIN {if (dur < 120) exit 0; exit 1}''\n    if [ $? -eq 0 ]; then\n      echo
        \"true\" > within_limit.txt\n    else\n      echo \"false\" > within_limit.txt\n    fi\n  >>>\n\n  output
        {\n    Float duration_seconds = read_float(\"duration.txt\")\n    Boolean
        within_limit = read_boolean(\"within_limit.txt\")\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n    cpu: 1\n    memory: \"1 GB\"\n  }\n}\n\ntask Hostname
        {\n  input {\n    String expected_image\n    Float start_time  # Add start_time
        as input to create dependency\n  }\n\n  command <<<\n    # Split expected
        image into name and tag\n    EXPECTED_IMAGE_NAME=$(echo \"~{expected_image}\"
        | cut -d'':'' -f1)\n    EXPECTED_TAG=$(echo \"~{expected_image}\" | cut -d'':''
        -f2)\n\n    # Get current image info\n    CURRENT_IMAGE=$(grep \"ID=\" /etc/os-release
        | head -n1 | cut -d''='' -f2)\n    CURRENT_VERSION=$(grep \"VERSION_ID=\"
        /etc/os-release | cut -d''\"'' -f2)\n\n    # Compare image name\n    if [[
        \"$CURRENT_IMAGE\" != \"$EXPECTED_IMAGE_NAME\" ]]; then\n      echo \"Error:
        Expected Docker image $EXPECTED_IMAGE_NAME but got: $CURRENT_IMAGE\"\n      exit
        1\n    fi\n\n    # Compare version/tag\n    if [[ \"$CURRENT_VERSION\" !=
        \"$EXPECTED_TAG\" ]]; then\n      echo \"Error: Expected version $EXPECTED_TAG
        but got: $CURRENT_VERSION\"\n      exit 1\n    fi\n\n    echo \"Verified Docker
        Image: $CURRENT_IMAGE:$CURRENT_VERSION\"\n    echo \"Expected Image: ~{expected_image}\"\n    echo
        \"Hostname: $(hostname)\"\n  >>>\n\n  output {\n    File out = stdout()\n  }\n\n  runtime
        {\n    cpu: 1\n    memory: \"1 GB\"\n    docker: \"~{expected_image}\"\n  }\n\n  parameter_meta
        {\n    expected_image: \"Docker image that should be running this task\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"HelloDockerHostname.docker_image\":\"ubuntu:20.04\"}","workflowUrl":"","labels":"{}"},"calls":{"HelloDockerHostname.GetStartTime":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetStartTime/execution/stdout","backendStatus":"Done","commandLine":"date
        +%s.%N","shardIndex":-1,"outputs":{"timestamp":1739260006.4385638},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063648","backend":"gizmo","start":"2025-02-11T07:46:41.344Z","end":"2025-02-11T07:47:14.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetStartTime/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetStartTime","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:46:42.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:14.177Z"},{"startTime":"2025-02-11T07:46:41.344Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:46:42.678Z"},{"startTime":"2025-02-11T07:46:41.344Z","description":"Pending","endTime":"2025-02-11T07:46:41.344Z"},{"startTime":"2025-02-11T07:46:42.678Z","description":"PreparingJob","endTime":"2025-02-11T07:46:42.689Z"},{"startTime":"2025-02-11T07:47:14.177Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:14.332Z"},{"startTime":"2025-02-11T07:46:42.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:46:42.678Z"}]}],"HelloDockerHostname.Hostname":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout","backendStatus":"Done","commandLine":"#
        Split expected image into name and tag\nEXPECTED_IMAGE_NAME=$(echo \"ubuntu:20.04\"
        | cut -d'':'' -f1)\nEXPECTED_TAG=$(echo \"ubuntu:20.04\" | cut -d'':'' -f2)\n\n#
        Get current image info\nCURRENT_IMAGE=$(grep \"ID=\" /etc/os-release | head
        -n1 | cut -d''='' -f2)\nCURRENT_VERSION=$(grep \"VERSION_ID=\" /etc/os-release
        | cut -d''\"'' -f2)\n\n# Compare image name\nif [[ \"$CURRENT_IMAGE\" != \"$EXPECTED_IMAGE_NAME\"
        ]]; then\n  echo \"Error: Expected Docker image $EXPECTED_IMAGE_NAME but got:
        $CURRENT_IMAGE\"\n  exit 1\nfi\n\n# Compare version/tag\nif [[ \"$CURRENT_VERSION\"
        != \"$EXPECTED_TAG\" ]]; then\n  echo \"Error: Expected version $EXPECTED_TAG
        but got: $CURRENT_VERSION\"\n  exit 1\nfi\n\necho \"Verified Docker Image:
        $CURRENT_IMAGE:$CURRENT_VERSION\"\necho \"Expected Image: ubuntu:20.04\"\necho
        \"Hostname: $(hostname)\"","shardIndex":-1,"outputs":{"out":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"start_time":1739260006.4385638,"expected_image":"ubuntu:20.04"},"returnCode":0,"jobId":"9063762","backend":"gizmo","start":"2025-02-11T07:47:16.017Z","end":"2025-02-11T07:47:57.331Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:16.018Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:22.677Z"},{"startTime":"2025-02-11T07:47:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:22.677Z"},{"startTime":"2025-02-11T07:47:16.017Z","description":"Pending","endTime":"2025-02-11T07:47:16.018Z"},{"startTime":"2025-02-11T07:47:22.684Z","description":"RunningJob","endTime":"2025-02-11T07:47:56.635Z"},{"startTime":"2025-02-11T07:47:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:22.684Z"},{"startTime":"2025-02-11T07:47:56.635Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:57.331Z"}]}],"HelloDockerHostname.GetEndTime":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetEndTime/execution/stdout","backendStatus":"Done","commandLine":"date
        +%s.%N","shardIndex":-1,"outputs":{"timestamp":1739260086.453288},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"hostname_done":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout"},"returnCode":0,"jobId":"9063812","backend":"gizmo","start":"2025-02-11T07:47:58.858Z","end":"2025-02-11T07:48:36.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetEndTime/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetEndTime","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:48:02.677Z","description":"PreparingJob","endTime":"2025-02-11T07:48:02.685Z"},{"startTime":"2025-02-11T07:48:02.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:48:02.677Z"},{"startTime":"2025-02-11T07:48:35.576Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:48:36.332Z"},{"startTime":"2025-02-11T07:47:58.858Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:48:02.677Z"},{"startTime":"2025-02-11T07:47:58.858Z","description":"Pending","endTime":"2025-02-11T07:47:58.858Z"},{"startTime":"2025-02-11T07:48:02.685Z","description":"RunningJob","endTime":"2025-02-11T07:48:35.576Z"}]}],"HelloDockerHostname.ValidateExecutionTime":[{"executionStatus":"Running","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-ValidateExecutionTime/execution/stdout","backendStatus":"Done","commandLine":"#
        Calculate duration using awk for floating point arithmetic\nduration=$(awk
        \"BEGIN {print 1.739260086453288E9 - 1.7392600064385638E9}\")\necho \"$duration\"
        > duration.txt\n\n# Check if duration is less than 120 seconds (2 minutes)\nawk
        -v dur=\"$duration\" ''BEGIN {if (dur < 120) exit 0; exit 1}''\nif [ $? -eq
        0 ]; then\n  echo \"true\" > within_limit.txt\nelse\n  echo \"false\" > within_limit.txt\nfi","shardIndex":-1,"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"end_time":1739260086.453288,"start_time":1739260006.4385638},"jobId":"9063836","backend":"gizmo","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","attempt":1,"start":"2025-02-11T07:48:37.617Z","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-ValidateExecutionTime/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-ValidateExecutionTime"}]},"outputs":{},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7","actualWorkflowLanguage":"WDL","status":"Running","start":"2025-02-11T07:46:40.286Z","id":"d958d760-e7ff-4d55-9b74-90113c0dc1d7","inputs":{"docker_image":"ubuntu:20.04"},"labels":{"cromwell-workflow-id":"cromwell-d958d760-e7ff-4d55-9b74-90113c0dc1d7"},"submission":"2025-02-11T07:38:45.395Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:26 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '12728'
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - gizmoj32.fhcrc.org:35541
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://gizmoj32.fhcrc.org:35541/api/workflows/v1/d958d760-e7ff-4d55-9b74-90113c0dc1d7/metadata?expandSubWorkflows=true
  response:
    body:
      string: '{"workflowName":"HelloDockerHostname","workflowProcessingEvents":[{"cromwellId":"cromid-fd06105","description":"Finished","timestamp":"2025-02-11T07:49:23.521Z","cromwellVersion":"87"},{"cromwellId":"cromid-fd06105","description":"PickedUp","timestamp":"2025-02-11T07:46:40.286Z","cromwellVersion":"87"}],"actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version
        1.0\n## This is a test workflow that returns the Docker image name and tag\n##
        and measures execution time of the Hostname task.\n\n#### WORKFLOW DEFINITION\n\nworkflow
        HelloDockerHostname {\n  input {\n    String docker_image = \"ubuntu:20.04\"  #
        Default value but can be overridden\n  }\n\n  call GetStartTime\n\n  call
        Hostname {\n    input:\n      expected_image = docker_image,\n      start_time
        = GetStartTime.timestamp  # Add dependency on start time\n  }\n\n  call GetEndTime
        {\n    input:\n      hostname_done = Hostname.out  # Add dependency on Hostname
        completion\n  }\n\n  call ValidateExecutionTime {\n    input:\n      start_time
        = GetStartTime.timestamp,\n      end_time = GetEndTime.timestamp\n  }\n\n  output
        {\n    File stdout = Hostname.out\n    Float execution_time_seconds = ValidateExecutionTime.duration_seconds\n    Boolean
        within_time_limit = ValidateExecutionTime.within_limit\n  }\n\n  parameter_meta
        {\n    docker_image: \"Docker image to run the task in (e.g. ubuntu:latest)\"\n  }\n}\n\n####
        TASK DEFINITIONS\n\ntask GetStartTime {\n  command <<<\n    date +%s.%N\n  >>>\n\n  output
        {\n    Float timestamp = read_float(stdout())\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n    cpu: 1\n    memory: \"1 GB\"\n  }\n}\n\ntask GetEndTime
        {\n  input {\n    File hostname_done  # Add dependency on Hostname completion\n  }\n\n  command
        <<<\n    date +%s.%N\n  >>>\n\n  output {\n    Float timestamp = read_float(stdout())\n  }\n\n  runtime
        {\n    docker: \"ubuntu:20.04\"\n    cpu: 1\n    memory: \"1 GB\"\n  }\n}\n\ntask
        ValidateExecutionTime {\n  input {\n    Float start_time\n    Float end_time\n  }\n\n  command
        <<<\n    # Calculate duration using awk for floating point arithmetic\n    duration=$(awk
        \"BEGIN {print ~{end_time} - ~{start_time}}\")\n    echo \"$duration\" > duration.txt\n    \n    #
        Check if duration is less than 120 seconds (2 minutes)\n    awk -v dur=\"$duration\"
        ''BEGIN {if (dur < 120) exit 0; exit 1}''\n    if [ $? -eq 0 ]; then\n      echo
        \"true\" > within_limit.txt\n    else\n      echo \"false\" > within_limit.txt\n    fi\n  >>>\n\n  output
        {\n    Float duration_seconds = read_float(\"duration.txt\")\n    Boolean
        within_limit = read_boolean(\"within_limit.txt\")\n  }\n\n  runtime {\n    docker:
        \"ubuntu:20.04\"\n    cpu: 1\n    memory: \"1 GB\"\n  }\n}\n\ntask Hostname
        {\n  input {\n    String expected_image\n    Float start_time  # Add start_time
        as input to create dependency\n  }\n\n  command <<<\n    # Split expected
        image into name and tag\n    EXPECTED_IMAGE_NAME=$(echo \"~{expected_image}\"
        | cut -d'':'' -f1)\n    EXPECTED_TAG=$(echo \"~{expected_image}\" | cut -d'':''
        -f2)\n\n    # Get current image info\n    CURRENT_IMAGE=$(grep \"ID=\" /etc/os-release
        | head -n1 | cut -d''='' -f2)\n    CURRENT_VERSION=$(grep \"VERSION_ID=\"
        /etc/os-release | cut -d''\"'' -f2)\n\n    # Compare image name\n    if [[
        \"$CURRENT_IMAGE\" != \"$EXPECTED_IMAGE_NAME\" ]]; then\n      echo \"Error:
        Expected Docker image $EXPECTED_IMAGE_NAME but got: $CURRENT_IMAGE\"\n      exit
        1\n    fi\n\n    # Compare version/tag\n    if [[ \"$CURRENT_VERSION\" !=
        \"$EXPECTED_TAG\" ]]; then\n      echo \"Error: Expected version $EXPECTED_TAG
        but got: $CURRENT_VERSION\"\n      exit 1\n    fi\n\n    echo \"Verified Docker
        Image: $CURRENT_IMAGE:$CURRENT_VERSION\"\n    echo \"Expected Image: ~{expected_image}\"\n    echo
        \"Hostname: $(hostname)\"\n  >>>\n\n  output {\n    File out = stdout()\n  }\n\n  runtime
        {\n    cpu: 1\n    memory: \"1 GB\"\n    docker: \"~{expected_image}\"\n  }\n\n  parameter_meta
        {\n    expected_image: \"Docker image that should be running this task\"\n  }\n}\n","root":"","options":"{\n  \"read_from_cache\":
        false,\n  \"workflow_failure_mode\": \"ContinueWhilePossible\",\n  \"write_to_cache\":
        false\n}","inputs":"{\"HelloDockerHostname.docker_image\":\"ubuntu:20.04\"}","workflowUrl":"","labels":"{}"},"calls":{"HelloDockerHostname.GetStartTime":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetStartTime/execution/stdout","backendStatus":"Done","commandLine":"date
        +%s.%N","shardIndex":-1,"outputs":{"timestamp":1739260006.4385638},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{},"returnCode":0,"jobId":"9063648","backend":"gizmo","start":"2025-02-11T07:46:41.344Z","end":"2025-02-11T07:47:14.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetStartTime/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetStartTime","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:46:42.689Z","description":"RunningJob","endTime":"2025-02-11T07:47:14.177Z"},{"startTime":"2025-02-11T07:46:41.344Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:46:42.678Z"},{"startTime":"2025-02-11T07:46:41.344Z","description":"Pending","endTime":"2025-02-11T07:46:41.344Z"},{"startTime":"2025-02-11T07:46:42.678Z","description":"PreparingJob","endTime":"2025-02-11T07:46:42.689Z"},{"startTime":"2025-02-11T07:47:14.177Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:14.332Z"},{"startTime":"2025-02-11T07:46:42.678Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:46:42.678Z"}]}],"HelloDockerHostname.Hostname":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout","backendStatus":"Done","commandLine":"#
        Split expected image into name and tag\nEXPECTED_IMAGE_NAME=$(echo \"ubuntu:20.04\"
        | cut -d'':'' -f1)\nEXPECTED_TAG=$(echo \"ubuntu:20.04\" | cut -d'':'' -f2)\n\n#
        Get current image info\nCURRENT_IMAGE=$(grep \"ID=\" /etc/os-release | head
        -n1 | cut -d''='' -f2)\nCURRENT_VERSION=$(grep \"VERSION_ID=\" /etc/os-release
        | cut -d''\"'' -f2)\n\n# Compare image name\nif [[ \"$CURRENT_IMAGE\" != \"$EXPECTED_IMAGE_NAME\"
        ]]; then\n  echo \"Error: Expected Docker image $EXPECTED_IMAGE_NAME but got:
        $CURRENT_IMAGE\"\n  exit 1\nfi\n\n# Compare version/tag\nif [[ \"$CURRENT_VERSION\"
        != \"$EXPECTED_TAG\" ]]; then\n  echo \"Error: Expected version $EXPECTED_TAG
        but got: $CURRENT_VERSION\"\n  exit 1\nfi\n\necho \"Verified Docker Image:
        $CURRENT_IMAGE:$CURRENT_VERSION\"\necho \"Expected Image: ubuntu:20.04\"\necho
        \"Hostname: $(hostname)\"","shardIndex":-1,"outputs":{"out":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout"},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"start_time":1739260006.4385638,"expected_image":"ubuntu:20.04"},"returnCode":0,"jobId":"9063762","backend":"gizmo","start":"2025-02-11T07:47:16.017Z","end":"2025-02-11T07:47:57.331Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:47:16.018Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:47:22.677Z"},{"startTime":"2025-02-11T07:47:22.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:47:22.677Z"},{"startTime":"2025-02-11T07:47:16.017Z","description":"Pending","endTime":"2025-02-11T07:47:16.018Z"},{"startTime":"2025-02-11T07:47:22.684Z","description":"RunningJob","endTime":"2025-02-11T07:47:56.635Z"},{"startTime":"2025-02-11T07:47:22.677Z","description":"PreparingJob","endTime":"2025-02-11T07:47:22.684Z"},{"startTime":"2025-02-11T07:47:56.635Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:47:57.331Z"}]}],"HelloDockerHostname.GetEndTime":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetEndTime/execution/stdout","backendStatus":"Done","commandLine":"date
        +%s.%N","shardIndex":-1,"outputs":{"timestamp":1739260086.453288},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"hostname_done":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout"},"returnCode":0,"jobId":"9063812","backend":"gizmo","start":"2025-02-11T07:47:58.858Z","end":"2025-02-11T07:48:36.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetEndTime/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-GetEndTime","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:48:02.677Z","description":"PreparingJob","endTime":"2025-02-11T07:48:02.685Z"},{"startTime":"2025-02-11T07:48:02.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:48:02.677Z"},{"startTime":"2025-02-11T07:48:35.576Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:48:36.332Z"},{"startTime":"2025-02-11T07:47:58.858Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:48:02.677Z"},{"startTime":"2025-02-11T07:47:58.858Z","description":"Pending","endTime":"2025-02-11T07:47:58.858Z"},{"startTime":"2025-02-11T07:48:02.685Z","description":"RunningJob","endTime":"2025-02-11T07:48:35.576Z"}]}],"HelloDockerHostname.ValidateExecutionTime":[{"executionStatus":"Done","stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-ValidateExecutionTime/execution/stdout","backendStatus":"Done","commandLine":"#
        Calculate duration using awk for floating point arithmetic\nduration=$(awk
        \"BEGIN {print 1.739260086453288E9 - 1.7392600064385638E9}\")\necho \"$duration\"
        > duration.txt\n\n# Check if duration is less than 120 seconds (2 minutes)\nawk
        -v dur=\"$duration\" ''BEGIN {if (dur < 120) exit 0; exit 1}''\nif [ $? -eq
        0 ]; then\n  echo \"true\" > within_limit.txt\nelse\n  echo \"false\" > within_limit.txt\nfi","shardIndex":-1,"outputs":{"within_limit":true,"duration_seconds":80.0147},"runtimeAttributes":{"failOnStderr":"false","partition":"campus-new","continueOnReturnCode":"0","docker":"ubuntu:20.04","modules":"","gpus":"0","maxRetries":"0","cpu":"1","memory":"1
        GB"},"callCaching":{"allowResultReuse":false,"effectiveCallCachingMode":"CallCachingOff"},"inputs":{"end_time":1739260086.453288,"start_time":1739260006.4385638},"returnCode":0,"jobId":"9063836","backend":"gizmo","start":"2025-02-11T07:48:37.617Z","end":"2025-02-11T07:49:22.332Z","dockerImageUsed":"ubuntu@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b","stderr":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-ValidateExecutionTime/execution/stderr","callRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-ValidateExecutionTime","attempt":1,"executionEvents":[{"startTime":"2025-02-11T07:48:42.677Z","description":"WaitingForValueStore","endTime":"2025-02-11T07:48:42.677Z"},{"startTime":"2025-02-11T07:48:42.677Z","description":"PreparingJob","endTime":"2025-02-11T07:48:42.683Z"},{"startTime":"2025-02-11T07:48:37.617Z","description":"RequestingExecutionToken","endTime":"2025-02-11T07:48:42.677Z"},{"startTime":"2025-02-11T07:49:22.070Z","description":"UpdatingJobStore","endTime":"2025-02-11T07:49:22.332Z"},{"startTime":"2025-02-11T07:48:42.683Z","description":"RunningJob","endTime":"2025-02-11T07:49:22.070Z"},{"startTime":"2025-02-11T07:48:37.617Z","description":"Pending","endTime":"2025-02-11T07:48:37.617Z"}]}]},"outputs":{"HelloDockerHostname.within_time_limit":true,"HelloDockerHostname.execution_time_seconds":80.0147,"HelloDockerHostname.stdout":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7/call-Hostname/execution/stdout"},"workflowRoot":"/redacted/_DaSL/user/svc_proof_test/cromwell-scratch/HelloDockerHostname/d958d760-e7ff-4d55-9b74-90113c0dc1d7","actualWorkflowLanguage":"WDL","status":"Succeeded","end":"2025-02-11T07:49:23.521Z","start":"2025-02-11T07:46:40.286Z","id":"d958d760-e7ff-4d55-9b74-90113c0dc1d7","inputs":{"docker_image":"ubuntu:20.04"},"labels":{"cromwell-workflow-id":"cromwell-d958d760-e7ff-4d55-9b74-90113c0dc1d7"},"submission":"2025-02-11T07:38:45.395Z"}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 11 Feb 2025 07:49:31 GMT
      Server:
      - nginx/1.25.3
      Transfer-Encoding:
      - chunked
      content-length:
      - '13934'
    status:
      code: 200
      message: OK
version: 1
